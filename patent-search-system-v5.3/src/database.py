# src/database.py - å¢å¼·ç‰ˆè³‡æ–™åº«æ¨¡çµ„

import asyncio
import logging
import json
import hashlib
import uuid
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine, async_sessionmaker
from sqlalchemy.orm import DeclarativeBase
from sqlalchemy import Column, Integer, String, Text, DateTime, Float, Boolean, func, select, JSON
from datetime import datetime
from src.config import settings
from datetime import timedelta
from typing import List, Dict, Optional

logger = logging.getLogger(__name__)

# å‰µå»ºç•°æ­¥å¼•æ“
engine = create_async_engine(
    settings.DATABASE_URL,
    echo=settings.DEBUG,
    pool_pre_ping=True
)

# å‰µå»ºæœƒè©±å·¥å» 
async_session_maker = async_sessionmaker(
    engine, 
    class_=AsyncSession, 
    expire_on_commit=False
)

class Base(DeclarativeBase):
    """æ•¸æ“šåº«åŸºé¡"""
    pass

class SearchHistory(Base):
    """æœç´¢æ­·å²è¡¨"""
    __tablename__ = "search_history"
    
    id = Column(Integer, primary_key=True, index=True)
    search_type = Column(String(50), nullable=False)  # tech_description, condition, excel_analysis
    query_text = Column(Text, nullable=True)
    search_params = Column(Text, nullable=True)  # JSONæ ¼å¼
    results_count = Column(Integer, default=0)
    execution_time = Column(Float, default=0.0)
    user_code_hash = Column(String(64), nullable=True)  # åŠ å¯†å¾Œçš„ç”¨æˆ¶ä»£ç¢¼
    created_at = Column(DateTime, default=datetime.utcnow)

class PatentCache(Base):
    """å°ˆåˆ©ç·©å­˜è¡¨"""
    __tablename__ = "patent_cache"
    
    id = Column(Integer, primary_key=True, index=True)
    patent_number = Column(String(100), unique=True, index=True)
    title = Column(Text, nullable=True)
    abstract = Column(Text, nullable=True)
    claims = Column(Text, nullable=True)
    applicants = Column(Text, nullable=True)  # JSONæ ¼å¼
    technical_features = Column(Text, nullable=True)  # JSONæ ¼å¼ - æŠ€è¡“ç‰¹å¾µ
    technical_effects = Column(Text, nullable=True)   # JSONæ ¼å¼ - æŠ€è¡“åŠŸæ•ˆ
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

# ğŸ†• æ–°å¢ï¼šæŠ€è¡“æè¿°æŸ¥è©¢æ­·å²è¡¨
class TechQueryHistory(Base):
    """æŠ€è¡“æè¿°æŸ¥è©¢æ­·å²è¡¨"""
    __tablename__ = "tech_query_history"
    
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(String(64), nullable=False, index=True, unique=True)
    tech_description = Column(Text, nullable=False)  # åŸå§‹æŠ€è¡“æè¿°
    generated_keywords = Column(JSON, nullable=True)  # Qwenç”Ÿæˆçš„é—œéµå­—
    selected_keywords = Column(JSON, nullable=True)   # ç”¨æˆ¶é¸æ“‡çš„é—œéµå­—
    custom_keywords = Column(JSON, nullable=True)     # ç”¨æˆ¶è‡ªå®šç¾©é—œéµå­—
    final_keywords = Column(JSON, nullable=True)      # æœ€çµ‚ä½¿ç”¨çš„é—œéµå­—
    search_logic = Column(String(20), default='traditional')  # traditional, and_or
    results_count = Column(Integer, default=0)
    execution_time = Column(Float, default=0.0)
    user_code_hash = Column(String(64), nullable=True)
    created_at = Column(DateTime, default=datetime.utcnow)

# ğŸ†• æ–°å¢ï¼šæª¢ç´¢çµæœæš«å­˜è¡¨
class SearchResultCache(Base):
    """æª¢ç´¢çµæœæš«å­˜è¡¨ - ç”¨æ–¼å•ç­”åŠŸèƒ½"""
    __tablename__ = "search_result_cache"
    
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(String(64), nullable=False, index=True)  # æœƒè©±ID
    search_type = Column(String(50), nullable=False)  # tech_description, condition, excel_analysis
    patent_sequence = Column(Integer, nullable=False)  # å°ˆåˆ©åºè™Ÿ
    patent_title = Column(Text, nullable=True)         # å°ˆåˆ©åç¨±
    patent_number = Column(String(100), nullable=True) # å…¬é–‹å…¬å‘Šè™Ÿ
    applicants = Column(Text, nullable=True)           # ç”³è«‹äºº
    country = Column(String(10), nullable=True)        # åœ‹å®¶
    abstract = Column(Text, nullable=True)             # æ‘˜è¦
    claims = Column(Text, nullable=True)               # å°ˆåˆ©ç¯„åœ
    technical_features = Column(JSON, nullable=True)   # æŠ€è¡“ç‰¹å¾µ
    technical_effects = Column(JSON, nullable=True)    # æŠ€è¡“åŠŸæ•ˆ
    full_data = Column(JSON, nullable=True)            # å®Œæ•´æ•¸æ“šï¼ˆJSONæ ¼å¼ï¼‰
    created_at = Column(DateTime, default=datetime.utcnow)
    expires_at = Column(DateTime, nullable=True)       # éæœŸæ™‚é–“ï¼ˆ7å¤©å¾Œï¼‰

# ğŸ†• æ–°å¢ï¼šå•ç­”æ­·å²è¡¨
class QAHistory(Base):
    """å•ç­”æ­·å²è¡¨"""
    __tablename__ = "qa_history"
    
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(String(64), nullable=False, index=True)  # é—œè¯çš„æª¢ç´¢æœƒè©±ID
    question = Column(Text, nullable=False)                      # ç”¨æˆ¶å•é¡Œ
    answer = Column(Text, nullable=True)                         # QWENå›ç­”
    referenced_patents = Column(JSON, nullable=True)             # å¼•ç”¨çš„å°ˆåˆ©åºè™Ÿåˆ—è¡¨
    execution_time = Column(Float, default=0.0)                 # åŸ·è¡Œæ™‚é–“
    created_at = Column(DateTime, default=datetime.utcnow)

class UserFeedback(Base):
    """ç”¨æˆ¶åé¥‹è¡¨"""
    __tablename__ = "user_feedback"
    
    id = Column(Integer, primary_key=True, index=True)
    session_id = Column(String(64), nullable=False, index=True)
    tech_description = Column(Text, nullable=False)
    tech_description_hash = Column(String(64), nullable=False, index=True)
    generated_keywords = Column(Text, nullable=True)  # JSONæ ¼å¼ï¼šQwenç”Ÿæˆçš„é—œéµå­—
    selected_keywords = Column(Text, nullable=True)   # JSONæ ¼å¼ï¼šç”¨æˆ¶é¸æ“‡çš„é—œéµå­—
    custom_keywords = Column(Text, nullable=True)     # JSONæ ¼å¼ï¼šç”¨æˆ¶è‡ªå®šç¾©é—œéµå­—
    final_keywords = Column(Text, nullable=True)      # JSONæ ¼å¼ï¼šæœ€çµ‚ä½¿ç”¨çš„é—œéµå­—
    search_results_count = Column(Integer, default=0)  # æœç´¢çµæœæ•¸é‡
    execution_time = Column(Float, default=0.0)       # åŸ·è¡Œæ™‚é–“
    satisfaction_score = Column(Integer, nullable=True)  # æ»¿æ„åº¦è©•åˆ†(1-5)
    user_comment = Column(Text, nullable=True)        # ç”¨æˆ¶è©•è«–
    created_at = Column(DateTime, default=datetime.utcnow)

class KeywordQuality(Base):
    """é—œéµå­—è³ªé‡è©•ä¼°è¡¨"""
    __tablename__ = "keyword_quality"
    
    id = Column(Integer, primary_key=True, index=True)
    tech_description_hash = Column(String(64), nullable=False, index=True)
    generated_keyword = Column(String(100), nullable=False, index=True)
    selected_by_user = Column(Boolean, default=False)
    selection_count = Column(Integer, default=0)
    rejection_count = Column(Integer, default=0)
    quality_score = Column(Float, default=0.5)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

async def init_db():
    """åˆå§‹åŒ–è³‡æ–™åº«"""
    try:
        logger.info("ğŸ—„ï¸ é–‹å§‹åˆå§‹åŒ–å¢å¼·ç‰ˆè³‡æ–™åº«...")
        
        # å‰µå»ºæ‰€æœ‰è¡¨
        async with engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)
        
        logger.info("âœ… å¢å¼·ç‰ˆè³‡æ–™åº«åˆå§‹åŒ–å®Œæˆ")
        logger.info("ğŸ†• æ–°å¢åŠŸèƒ½ï¼šæª¢ç´¢æ­·å²å­˜å„²ã€çµæœæš«å­˜ã€å•ç­”åŠŸèƒ½")
        
    except Exception as e:
        logger.error(f"âŒ è³‡æ–™åº«åˆå§‹åŒ–å¤±æ•—: {e}")
        raise

async def get_db_session():
    """ç²å–è³‡æ–™åº«æœƒè©±"""
    async with async_session_maker() as session:
        try:
            yield session
        finally:
            await session.close()

async def close_db():
    """é—œé–‰è³‡æ–™åº«é€£æ¥"""
    await engine.dispose()
    logger.info("ğŸ”š è³‡æ–™åº«é€£æ¥å·²é—œé–‰")

class DatabaseManager:
    """å¢å¼·ç‰ˆè³‡æ–™åº«ç®¡ç†å™¨"""
    
    @staticmethod
    def _hash_text(text: str) -> str:
        """ç”Ÿæˆæ–‡æœ¬çš„MD5 hash"""
        return hashlib.md5(text.encode('utf-8')).hexdigest()
    
    @staticmethod
    async def save_search_history(
        search_type: str,
        query_text: str = None,
        search_params: dict = None,
        results_count: int = 0,
        execution_time: float = 0.0,
        user_code_hash: str = None
    ):
        """ä¿å­˜æœç´¢æ­·å²"""
        try:
            async with async_session_maker() as session:
                history = SearchHistory(
                    search_type=search_type,
                    query_text=query_text,
                    search_params=json.dumps(search_params, ensure_ascii=False) if search_params else None,
                    results_count=results_count,
                    execution_time=execution_time,
                    user_code_hash=user_code_hash
                )
                session.add(history)
                await session.commit()
                logger.debug(f"æœç´¢æ­·å²å·²ä¿å­˜: {search_type}")
        except Exception as e:
            logger.error(f"ä¿å­˜æœç´¢æ­·å²å¤±æ•—: {e}")

    # ğŸ†• æ–°å¢ï¼šä¿å­˜æŠ€è¡“æè¿°æŸ¥è©¢æ­·å²
    @staticmethod
    async def save_tech_query_history(
        session_id: str,
        tech_description: str,
        generated_keywords: list,
        selected_keywords: list,
        custom_keywords: list,
        final_keywords: list,
        search_logic: str,
        results_count: int,
        execution_time: float,
        user_code_hash: str = None
    ):
        """ä¿å­˜æŠ€è¡“æè¿°æŸ¥è©¢æ­·å²"""
        try:
            async with async_session_maker() as session:
                tech_query = TechQueryHistory(
                    session_id=session_id,
                    tech_description=tech_description,
                    generated_keywords=generated_keywords,
                    selected_keywords=selected_keywords,
                    custom_keywords=custom_keywords,
                    final_keywords=final_keywords,
                    search_logic=search_logic,
                    results_count=results_count,
                    execution_time=execution_time,
                    user_code_hash=user_code_hash
                )
                session.add(tech_query)
                await session.commit()
                logger.info(f"æŠ€è¡“æè¿°æŸ¥è©¢æ­·å²å·²ä¿å­˜: {session_id}")
        except Exception as e:
            logger.error(f"ä¿å­˜æŠ€è¡“æè¿°æŸ¥è©¢æ­·å²å¤±æ•—: {e}")

   # ä¿®æ”¹ database.py ä¸­çš„ save_search_results_to_cache æ–¹æ³•

    # ä¿®æ”¹ database.py ä¸­çš„ save_search_results_to_cache æ–¹æ³•

    @staticmethod
    async def save_search_results_to_cache(
        session_id: str,
        search_type: str,
        results: list,
        expires_days: int = 7
    ):
        """ä¿å­˜æª¢ç´¢çµæœåˆ°æš«å­˜ï¼ŒæŒ‰æœå°‹é¡å‹åˆ†åˆ¥ä¿å­˜"""
        try:
            async with async_session_maker() as session:
                expires_at = datetime.utcnow() + timedelta(days=expires_days)

                # ğŸ†• ä¿®æ”¹ï¼šåªåˆªé™¤ç›¸åŒæœå°‹é¡å‹çš„èˆŠæ•¸æ“šï¼Œä¸æ˜¯å…¨éƒ¨åˆªé™¤
                existing_results = await session.execute(
                    select(SearchResultCache)
                    .where(SearchResultCache.session_id == session_id)
                    .where(SearchResultCache.search_type == search_type)  # ğŸ”§ åŠ å…¥æœå°‹é¡å‹æ¢ä»¶
                )
            
                for result in existing_results.scalars():
                    await session.delete(result)

                # ä¿å­˜æ–°çµæœ
                for i, result in enumerate(results):
                    cache_entry = SearchResultCache(
                        session_id=session_id,
                        search_type=search_type,
                        patent_sequence=result.get('åºè™Ÿ', i + 1),
                        patent_title=result.get('å°ˆåˆ©åç¨±', ''),
                        patent_number=result.get('å…¬é–‹å…¬å‘Šè™Ÿ', ''),
                        applicants=result.get('ç”³è«‹äºº', ''),
                        country=result.get('åœ‹å®¶', ''),
                        abstract=result.get('æ‘˜è¦', ''),
                        claims=result.get('å°ˆåˆ©ç¯„åœ', ''),
                        technical_features=result.get('æŠ€è¡“ç‰¹å¾µ', []),
                        technical_effects=result.get('æŠ€è¡“åŠŸæ•ˆ', []),
                        full_data=result,
                        expires_at=expires_at
                    )
                    session.add(cache_entry)

                await session.commit()
                logger.info(f"æª¢ç´¢çµæœå·²æš«å­˜: {session_id}, é¡å‹: {search_type}, {len(results)} ç­†å°ˆåˆ©")

        except Exception as e:
            logger.error(f"ä¿å­˜æª¢ç´¢çµæœåˆ°æš«å­˜å¤±æ•—: {e}")

    # ğŸ†• æ–°å¢ï¼šæ ¹æ“šæœå°‹é¡å‹ç²å–æš«å­˜çµæœ
    @staticmethod
    async def get_cached_search_results_by_type(
        session_id: str, 
        search_type: str = None
    ) -> List[Dict]:
        """æ ¹æ“šæœå°‹é¡å‹ç²å–æš«å­˜çµæœ"""
        try:
            async with async_session_maker() as session:
                query = select(SearchResultCache)\
                    .where(SearchResultCache.session_id == session_id)\
                    .where(SearchResultCache.expires_at > datetime.utcnow())

                if search_type:
                    query = query.where(SearchResultCache.search_type == search_type)

                query = query.order_by(SearchResultCache.search_type, SearchResultCache.patent_sequence)

                result = await session.execute(query)
                cached_results = result.scalars().all()

                if not cached_results:
                    logger.info(f"æœªæ‰¾åˆ°æœ‰æ•ˆçš„æš«å­˜çµæœ: {session_id}, é¡å‹: {search_type}")
                    return []

                # è½‰æ›ç‚ºå­—å…¸æ ¼å¼
                results = []
                for cache_entry in cached_results:
                    if cache_entry.full_data:
                        # ğŸ†• åŠ å…¥æœå°‹é¡å‹æ¨™è¨˜
                        result_data = cache_entry.full_data.copy()
                        result_data['_search_type'] = cache_entry.search_type
                        results.append(result_data)
                    else:
                    # å¾å€‹åˆ¥æ¬„ä½é‡å»º
                        results.append({
                            'åºè™Ÿ': cache_entry.patent_sequence,
                            'å°ˆåˆ©åç¨±': cache_entry.patent_title,
                            'å…¬é–‹å…¬å‘Šè™Ÿ': cache_entry.patent_number,
                            'ç”³è«‹äºº': cache_entry.applicants,
                            'åœ‹å®¶': cache_entry.country,
                            'æ‘˜è¦': cache_entry.abstract,
                            'å°ˆåˆ©ç¯„åœ': cache_entry.claims,
                            'æŠ€è¡“ç‰¹å¾µ': cache_entry.technical_features or [],
                            'æŠ€è¡“åŠŸæ•ˆ': cache_entry.technical_effects or [],
                            '_search_type': cache_entry.search_type  # ğŸ†• æ¨™è¨˜æœå°‹é¡å‹
                        })

                logger.info(f"ç²å–æš«å­˜çµæœ: {session_id}, é¡å‹: {search_type or 'å…¨éƒ¨'}, {len(results)} ç­†å°ˆåˆ©")
                return results

        except Exception as e:
            logger.error(f"ç²å–æš«å­˜æª¢ç´¢çµæœå¤±æ•—: {e}")
            return []

    # ğŸ†• æ–°å¢ï¼šç²å–å¯ç”¨çš„æœå°‹é¡å‹
    @staticmethod
    async def get_available_search_types(session_id: str) -> List[str]:
        """ç²å–è©²sessionå¯ç”¨çš„æœå°‹é¡å‹"""
        try:
            async with async_session_maker() as session:
                result = await session.execute(
                    select(SearchResultCache.search_type)
                    .where(SearchResultCache.session_id == session_id)
                    .where(SearchResultCache.expires_at > datetime.utcnow())
                    .distinct()
                )

                search_types = [row[0] for row in result.all()]
                return search_types

        except Exception as e:
            logger.error(f"ç²å–å¯ç”¨æœå°‹é¡å‹å¤±æ•—: {e}")
            return []

    # ğŸ†• æ–°å¢ï¼šç²å–æš«å­˜çš„æª¢ç´¢çµæœ
    @staticmethod
    async def get_cached_search_results(session_id: str) -> List[Dict]:
        """ç²å–æš«å­˜çš„æª¢ç´¢çµæœ"""
        try:
            async with async_session_maker() as session:
                result = await session.execute(
                    select(SearchResultCache)
                    .where(SearchResultCache.session_id == session_id)
                    .where(SearchResultCache.expires_at > datetime.utcnow())
                    .order_by(SearchResultCache.patent_sequence)
                )
                
                cached_results = result.scalars().all()
                
                if not cached_results:
                    logger.info(f"æœªæ‰¾åˆ°æœ‰æ•ˆçš„æš«å­˜çµæœ: {session_id}")
                    return []
                
                # è½‰æ›ç‚ºå­—å…¸æ ¼å¼
                results = []
                for cache_entry in cached_results:
                    if cache_entry.full_data:
                        results.append(cache_entry.full_data)
                    else:
                        # å¾å€‹åˆ¥æ¬„ä½é‡å»º
                        results.append({
                            'åºè™Ÿ': cache_entry.patent_sequence,
                            'å°ˆåˆ©åç¨±': cache_entry.patent_title,
                            'å…¬é–‹å…¬å‘Šè™Ÿ': cache_entry.patent_number,
                            'ç”³è«‹äºº': cache_entry.applicants,
                            'åœ‹å®¶': cache_entry.country,
                            'æ‘˜è¦': cache_entry.abstract,
                            'å°ˆåˆ©ç¯„åœ': cache_entry.claims,
                            'æŠ€è¡“ç‰¹å¾µ': cache_entry.technical_features or [],
                            'æŠ€è¡“åŠŸæ•ˆ': cache_entry.technical_effects or []
                        })
                
                logger.info(f"ç²å–æš«å­˜çµæœ: {session_id}, {len(results)} ç­†å°ˆåˆ©")
                return results
                
        except Exception as e:
            logger.error(f"ç²å–æš«å­˜æª¢ç´¢çµæœå¤±æ•—: {e}")
            return []

    # ğŸ†• æ–°å¢ï¼šæ ¹æ“šåºè™Ÿç²å–ç‰¹å®šå°ˆåˆ©
    @staticmethod
    async def get_patent_by_sequence(session_id: str, sequence: int) -> Optional[Dict]:
        """æ ¹æ“šåºè™Ÿç²å–ç‰¹å®šå°ˆåˆ©"""
        try:
            async with async_session_maker() as session:
                result = await session.execute(
                    select(SearchResultCache)
                    .where(SearchResultCache.session_id == session_id)
                    .where(SearchResultCache.patent_sequence == sequence)
                    .where(SearchResultCache.expires_at > datetime.utcnow())
                )
                
                cache_entry = result.scalar_one_or_none()
                
                if cache_entry:
                    if cache_entry.full_data:
                        return cache_entry.full_data
                    else:
                        return {
                            'åºè™Ÿ': cache_entry.patent_sequence,
                            'å°ˆåˆ©åç¨±': cache_entry.patent_title,
                            'å…¬é–‹å…¬å‘Šè™Ÿ': cache_entry.patent_number,
                            'ç”³è«‹äºº': cache_entry.applicants,
                            'åœ‹å®¶': cache_entry.country,
                            'æ‘˜è¦': cache_entry.abstract,
                            'å°ˆåˆ©ç¯„åœ': cache_entry.claims,
                            'æŠ€è¡“ç‰¹å¾µ': cache_entry.technical_features or [],
                            'æŠ€è¡“åŠŸæ•ˆ': cache_entry.technical_effects or []
                        }
                
                return None
                
        except Exception as e:
            logger.error(f"æ ¹æ“šåºè™Ÿç²å–å°ˆåˆ©å¤±æ•—: {e}")
            return None

    # ğŸ†• æ–°å¢ï¼šä¿å­˜å•ç­”æ­·å²
    @staticmethod
    async def save_qa_history(
        session_id: str,
        question: str,
        answer: str,
        referenced_patents: List[int] = None,
        execution_time: float = 0.0
    ):
        """ä¿å­˜å•ç­”æ­·å²"""
        try:
            async with async_session_maker() as session:
                qa_entry = QAHistory(
                    session_id=session_id,
                    question=question,
                    answer=answer,
                    referenced_patents=referenced_patents or [],
                    execution_time=execution_time
                )
                session.add(qa_entry)
                await session.commit()
                logger.info(f"å•ç­”æ­·å²å·²ä¿å­˜: {session_id}")
                
        except Exception as e:
            logger.error(f"ä¿å­˜å•ç­”æ­·å²å¤±æ•—: {e}")

    # ğŸ†• æ–°å¢ï¼šç²å–å•ç­”æ­·å²
    @staticmethod
    async def get_qa_history(session_id: str, limit: int = 10) -> List[Dict]:
        """ç²å–å•ç­”æ­·å²"""
        try:
            async with async_session_maker() as session:
                result = await session.execute(
                    select(QAHistory)
                    .where(QAHistory.session_id == session_id)
                    .order_by(QAHistory.created_at.desc())
                    .limit(limit)
                )
                
                qa_entries = result.scalars().all()
                
                history = []
                for entry in reversed(qa_entries):  # åè½‰ä»¥æ™‚é–“é †åºæ’åˆ—
                    history.append({
                        'question': entry.question,
                        'answer': entry.answer,
                        'referenced_patents': entry.referenced_patents,
                        'execution_time': entry.execution_time,
                        'created_at': entry.created_at.isoformat()
                    })
                
                return history
                
        except Exception as e:
            logger.error(f"ç²å–å•ç­”æ­·å²å¤±æ•—: {e}")
            return []

    # ğŸ†• æ–°å¢ï¼šæ¸…ç†éæœŸçš„æš«å­˜çµæœ
    @staticmethod
    async def cleanup_expired_cache():
        """æ¸…ç†éæœŸçš„æš«å­˜çµæœ"""
        try:
            async with async_session_maker() as session:
                # åˆªé™¤éæœŸçš„æœç´¢çµæœæš«å­˜
                result = await session.execute(
                    select(SearchResultCache)
                    .where(SearchResultCache.expires_at <= datetime.utcnow())
                )
                expired_entries = result.scalars().all()
                
                for entry in expired_entries:
                    await session.delete(entry)
                
                await session.commit()
                
                if expired_entries:
                    logger.info(f"æ¸…ç†äº† {len(expired_entries)} ç­†éæœŸçš„æš«å­˜çµæœ")
                
        except Exception as e:
            logger.error(f"æ¸…ç†éæœŸæš«å­˜å¤±æ•—: {e}")

    # ä¿ç•™åŸæœ‰æ–¹æ³•...
    @staticmethod
    async def cache_patent(patent_data: dict):
        """ç·©å­˜å°ˆåˆ©æ•¸æ“š"""
        try:
            async with async_session_maker() as session:
                patent_number = patent_data.get('publication_number')
                if not patent_number:
                    return
                
                # æŸ¥æ‰¾ç¾æœ‰è¨˜éŒ„
                result = await session.execute(
                    select(PatentCache).where(PatentCache.patent_number == patent_number)
                )
                existing = result.scalar_one_or_none()
                
                if existing:
                    # æ›´æ–°ç¾æœ‰è¨˜éŒ„
                    existing.title = patent_data.get('title')
                    existing.abstract = patent_data.get('abstract')
                    existing.claims = patent_data.get('claims')
                    existing.technical_features = json.dumps(patent_data.get('technical_features', []), ensure_ascii=False)
                    existing.technical_effects = json.dumps(patent_data.get('technical_effects', []), ensure_ascii=False)
                    existing.updated_at = datetime.utcnow()
                else:
                    # å‰µå»ºæ–°è¨˜éŒ„
                    cache_entry = PatentCache(
                        patent_number=patent_number,
                        title=patent_data.get('title'),
                        abstract=patent_data.get('abstract'),
                        claims=patent_data.get('claims'),
                        applicants=json.dumps(patent_data.get('applicants', []), ensure_ascii=False),
                        technical_features=json.dumps(patent_data.get('technical_features', []), ensure_ascii=False),
                        technical_effects=json.dumps(patent_data.get('technical_effects', []), ensure_ascii=False)
                    )
                    session.add(cache_entry)
                
                await session.commit()
                logger.debug(f"å°ˆåˆ©ç·©å­˜å·²æ›´æ–°: {patent_number}")
                
        except Exception as e:
            logger.error(f"ç·©å­˜å°ˆåˆ©æ•¸æ“šå¤±æ•—: {e}")

    @staticmethod
    async def save_user_feedback(
        session_id: str,
        tech_description: str,
        generated_keywords: list,
        selected_keywords: list,
        custom_keywords: list,
        final_keywords: list,
        search_results_count: int = 0,
        execution_time: float = 0.0,
        satisfaction_score: int = None,
        user_comment: str = None
    ):
        """ä¿å­˜ç”¨æˆ¶åé¥‹æ•¸æ“š"""
        try:
            async with async_session_maker() as session:
                tech_hash = DatabaseManager._hash_text(tech_description)
                
                feedback = UserFeedback(
                    session_id=session_id,
                    tech_description=tech_description,
                    tech_description_hash=tech_hash,
                    generated_keywords=json.dumps(generated_keywords, ensure_ascii=False),
                    selected_keywords=json.dumps(selected_keywords, ensure_ascii=False),
                    custom_keywords=json.dumps(custom_keywords, ensure_ascii=False),
                    final_keywords=json.dumps(final_keywords, ensure_ascii=False),
                    search_results_count=search_results_count,
                    execution_time=execution_time,
                    satisfaction_score=satisfaction_score,
                    user_comment=user_comment
                )
                session.add(feedback)
                await session.commit()
                logger.info(f"ç”¨æˆ¶åé¥‹å·²ä¿å­˜: session_id={session_id}")
                
                # åŒæ™‚æ›´æ–°é—œéµå­—è³ªé‡æ•¸æ“š
                await DatabaseManager._update_keyword_quality(
                    tech_description, generated_keywords, selected_keywords
                )
                
        except Exception as e:
            logger.error(f"ä¿å­˜ç”¨æˆ¶åé¥‹å¤±æ•—: {e}")
    
    @staticmethod
    async def _update_keyword_quality(
        tech_description: str, 
        generated_keywords: list, 
        selected_keywords: list
    ):
        """æ›´æ–°é—œéµå­—è³ªé‡çµ±è¨ˆ"""
        try:
            desc_hash = DatabaseManager._hash_text(tech_description)
            
            async with async_session_maker() as session:
                for keyword in generated_keywords:
                    # æŸ¥æ‰¾ç¾æœ‰è¨˜éŒ„
                    result = await session.execute(
                        select(KeywordQuality).where(
                            KeywordQuality.tech_description_hash == desc_hash,
                            KeywordQuality.generated_keyword == keyword
                        )
                    )
                    quality_record = result.scalar_one_or_none()
                    
                    if quality_record:
                        # æ›´æ–°ç¾æœ‰è¨˜éŒ„
                        if keyword in selected_keywords:
                            quality_record.selection_count += 1
                            quality_record.selected_by_user = True
                        else:
                            quality_record.rejection_count += 1
                        
                        # é‡æ–°è¨ˆç®—è³ªé‡åˆ†æ•¸
                        total = quality_record.selection_count + quality_record.rejection_count
                        quality_record.quality_score = quality_record.selection_count / total if total > 0 else 0.5
                        quality_record.updated_at = datetime.utcnow()
                    else:
                        # å‰µå»ºæ–°è¨˜éŒ„
                        selected = keyword in selected_keywords
                        quality_record = KeywordQuality(
                            tech_description_hash=desc_hash,
                            generated_keyword=keyword,
                            selected_by_user=selected,
                            selection_count=1 if selected else 0,
                            rejection_count=0 if selected else 1,
                            quality_score=1.0 if selected else 0.0
                        )
                        session.add(quality_record)
                
                await session.commit()
                
        except Exception as e:
            logger.error(f"æ›´æ–°é—œéµå­—è³ªé‡å¤±æ•—: {e}")

    @staticmethod
    async def get_feedback_statistics():
        """ç²å–åé¥‹çµ±è¨ˆæ•¸æ“š"""
        try:
            async with async_session_maker() as session:
                stats = {}
                
                # çµ±è¨ˆç¸½åé¥‹æ•¸é‡
                total_feedback_result = await session.execute(
                    select(func.count(UserFeedback.id))
                )
                stats["total_feedback"] = total_feedback_result.scalar()
                
                # ç²å–é—œéµå­—è³ªé‡çµ±è¨ˆ
                keyword_quality_result = await session.execute(
                    select(
                        func.avg(KeywordQuality.quality_score),
                        func.count(KeywordQuality.id)
                    )
                )
                avg_quality, keyword_count = keyword_quality_result.first()
                stats["keyword_quality"] = {
                    "average_score": float(avg_quality) if avg_quality else 0.0,
                    "total_keywords": keyword_count
                }
                
                # ç²å–æŠ€è¡“æè¿°æŸ¥è©¢çµ±è¨ˆ
                tech_query_result = await session.execute(
                    select(
                        func.count(TechQueryHistory.id),
                        func.avg(TechQueryHistory.execution_time),
                        func.avg(TechQueryHistory.results_count)
                    )
                )
                total_queries, avg_time, avg_results = tech_query_result.first()
                stats["tech_queries"] = {
                    "total_queries": total_queries or 0,
                    "average_execution_time": float(avg_time) if avg_time else 0.0,
                    "average_results_count": float(avg_results) if avg_results else 0.0
                }
                
                # ç²å–å•ç­”çµ±è¨ˆ
                qa_result = await session.execute(
                    select(
                        func.count(QAHistory.id),
                        func.avg(QAHistory.execution_time)
                    )
                )
                total_qa, avg_qa_time = qa_result.first()
                stats["qa_interactions"] = {
                    "total_questions": total_qa or 0,
                    "average_response_time": float(avg_qa_time) if avg_qa_time else 0.0
                }
                
                return stats
                
        except Exception as e:
            logger.error(f"ç²å–åé¥‹çµ±è¨ˆå¤±æ•—: {e}")
            return {}

    @staticmethod
    async def get_search_statistics():
        """ç²å–æœç´¢çµ±è¨ˆ"""
        try:
            async with async_session_maker() as session:
                # çµ±è¨ˆæœç´¢é¡å‹åˆ†å¸ƒ
                search_type_result = await session.execute(
                    select(SearchHistory.search_type, func.count(SearchHistory.id))
                    .group_by(SearchHistory.search_type)
                )
                
                search_distribution = {
                    row[0]: row[1] for row in search_type_result.fetchall()
                }
                
                # çµ±è¨ˆå¹³å‡åŸ·è¡Œæ™‚é–“
                avg_time_result = await session.execute(
                    select(
                        SearchHistory.search_type,
                        func.avg(SearchHistory.execution_time)
                    ).group_by(SearchHistory.search_type)
                )
                
                avg_execution_times = {
                    row[0]: float(row[1]) if row[1] else 0.0 
                    for row in avg_time_result.fetchall()
                }
                
                return {
                    "search_distribution": search_distribution,
                    "average_execution_times": avg_execution_times
                }
                
        except Exception as e:
            logger.error(f"ç²å–æœç´¢çµ±è¨ˆå¤±æ•—: {e}")
            return {}

