# src/services/improved_patent_processing_service.py - ä¿®å¾©ç”³è«‹äººå’Œåœ‹å®¶é¡¯ç¤º

import asyncio
import logging
import json
import time
from typing import List, Dict, Optional, Any
from datetime import datetime
from dataclasses import dataclass
from src.ai_services.qwen_service import QwenAPIService
from src.ai_services.gpss_service import GPSSAPIService
from src.config import settings
import pandas as pd
from io import BytesIO
import uuid
from typing import BinaryIO

logger = logging.getLogger(__name__)

@dataclass
class PatentProcessingResult:
    success: bool
    results: List[Dict[str, Any]] = None
    total_found: int = 0
    message: str = ""
    query_info: Dict[str, Any] = None
    error: str = ""

class ImprovedPatentProcessingService:
    BATCH_SIZE = 30
    BATCH_DELAY = 0.1
    MAX_CONCURRENT_REQUESTS = 16
    REQUEST_DELAY = 0.2
    MAX_RETRIES = 3
    RETRY_DELAY = 1.0
    
    def __init__(self):
        self.qwen_service = None
        self.gpss_service = None
        self.initialized = False
        self.verified_api_keys = set()
        self.semaphore = asyncio.Semaphore(self.MAX_CONCURRENT_REQUESTS)
        
    async def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰AIæœå‹™"""
        if self.initialized:
            return
            
        try:
            logger.info("ğŸš€ é–‹å§‹åˆå§‹åŒ–å°ˆåˆ©è™•ç†æœå‹™ï¼ˆä¿®å¾©ç”³è«‹äººå’Œåœ‹å®¶ç‰ˆæœ¬ï¼‰...")
            
            # åˆå§‹åŒ–Qwenæœå‹™
            self.qwen_service = QwenAPIService(settings.QWEN_API_URL)
            await self.qwen_service.initialize()
            logger.info("âœ… Qwenåˆå§‹åŒ–æˆåŠŸ")
            
            # åˆå§‹åŒ–çœŸå¯¦GPSSæœå‹™
            self.gpss_service = GPSSAPIService()
            await self.gpss_service.initialize()
            logger.info("âœ… GPSSåˆå§‹åŒ–æˆåŠŸï¼ˆå·²ä¿®å¾©ç”³è«‹äººå’Œåœ‹å®¶æ¬„ä½ï¼‰")
            
            self.initialized = True
            logger.info("å°ˆåˆ©è™•ç†æœå‹™åˆå§‹åŒ–å®Œæˆï¼ï¼ˆç”³è«‹äººå’Œåœ‹å®¶ä¿®å¾©ç‰ˆæœ¬ï¼‰")
            
        except Exception as e:
            logger.error(f"æœå‹™åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    async def close(self):
        """é—œé–‰æ‰€æœ‰æœå‹™"""
        if self.qwen_service:
            await self.qwen_service.close()
        if self.gpss_service:
            await self.gpss_service.close()
        logger.info("æ‰€æœ‰æœå‹™å·²é—œé–‰")

    async def verify_api_key(self, user_code: str) -> bool:
        """é©—è­‰GPSS APIå¯†é‘°"""
        try:
            if user_code in self.verified_api_keys:
                return True
            
            # åŸºæœ¬æ ¼å¼é©—è­‰
            if not user_code or len(user_code) < 16:
                logger.warning("APIå¯†é‘°æ ¼å¼ä¸æ­£ç¢º")
                return False
            
            # ä½¿ç”¨çœŸå¯¦GPSS APIæ¸¬è©¦é€£æ¥
            test_result = await self.gpss_service.test_api_connection(user_code)
            
            if test_result.get('success', False):
                self.verified_api_keys.add(user_code)
                logger.info(f"APIå¯†é‘°é©—è­‰æˆåŠŸ: {user_code[:8]}...")
                return True
            else:
                logger.warning(f"APIå¯†é‘°é©—è­‰å¤±æ•—: {test_result.get('message', 'Unknown error')}")
                return False
            
        except Exception as e:
            logger.error(f"APIå¯†é‘°é©—è­‰ç•°å¸¸: {e}")
            return False

    async def process_tech_description_search_with_keywords(
        self,
        description: str,
        keywords: List[str],
        user_code: str,
        max_results: int = 1000
    ) -> PatentProcessingResult:
        """æµç¨‹Aï¼šä½¿ç”¨å·²ç¢ºèªçš„é—œéµå­—åŸ·è¡ŒæŠ€è¡“æè¿°æŸ¥è©¢"""
        start_time = time.time()
        
        try:
            logger.info(f"ä½¿ç”¨ç¢ºèªé—œéµå­—åŸ·è¡ŒæŠ€è¡“æè¿°æŸ¥è©¢ï¼Œé—œéµå­—: {keywords}")
            
            # æ­¥é©Ÿ1ï¼šé©—è­‰APIå¯†é‘°
            if settings.REQUIRE_API_VALIDATION and not await self.verify_api_key(user_code):
                return PatentProcessingResult(
                    success=False,
                    error="GPSS APIå¯†é‘°é©—è­‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥å¯†é‘°æ˜¯å¦æ­£ç¢º"
                )
            
            # æ­¥é©Ÿ2ï¼šä½¿ç”¨æä¾›çš„é—œéµå­—æœç´¢å°ˆåˆ©
            raw_patents = await self._search_patents_with_keywords(keywords, user_code, max_results)
            
            if not raw_patents:
                return PatentProcessingResult(
                    success=True,
                    results=[],
                    total_found=0,
                    message="æœªæ‰¾åˆ°ç›¸é—œå°ˆåˆ©",
                    query_info={
                        "description": description,
                        "used_keywords": keywords,
                        "search_time": time.time() - start_time
                    }
                )
            
            logger.info(f"æœç´¢åˆ° {len(raw_patents)} ç­†åŸå§‹å°ˆåˆ©")
            
            # æ­¥é©Ÿ3ï¼šæ‰¹æ¬¡è™•ç†å°ˆåˆ©ï¼ˆåªç”ŸæˆæŠ€è¡“ç‰¹å¾µï¼‰
            processed_patents = await self._process_patents_with_batching(raw_patents)
            
            # æ­¥é©Ÿ4ï¼šæ ¼å¼åŒ–çµæœï¼ˆä¿®å¾©ç‰ˆæœ¬ï¼‰
            formatted_results = self._format_search_results_fixed(processed_patents)
            
            execution_time = time.time() - start_time
            
            return PatentProcessingResult(
                success=True,
                results=formatted_results,
                total_found=len(formatted_results),
                message=f"æŠ€è¡“æè¿°æŸ¥è©¢å®Œæˆï¼Œæ‰¾åˆ° {len(formatted_results)} ç­†å°ˆåˆ©",
                query_info={
                    "description": description,
                    "used_keywords": keywords,
                    "search_time": execution_time,
                    "processed_count": len(processed_patents),
                    "batch_processing": True
                }
            )
            
        except Exception as e:
            logger.error(f"ä½¿ç”¨é—œéµå­—æŸ¥è©¢å¤±æ•—: {e}")
            return PatentProcessingResult(
                success=False,
                error=f"ä½¿ç”¨é—œéµå­—æŸ¥è©¢å¤±æ•—: {str(e)}"
            )

    async def process_tech_description_search_with_and_or_logic(
        self,
        description: str,
        user_keywords: List[str],
        ai_keywords: List[str],
        user_code: str,
        max_results: int = 1000
    ) -> PatentProcessingResult:
        """æµç¨‹Aï¼šä½¿ç”¨ AND/OR é‚è¼¯åŸ·è¡ŒæŠ€è¡“æè¿°æŸ¥è©¢"""
        start_time = time.time()
        
        try:
            logger.info(f"ğŸ” ä½¿ç”¨AND/ORé‚è¼¯åŸ·è¡ŒæŠ€è¡“æè¿°æŸ¥è©¢")
            logger.info(f"ğŸ“ ç”¨æˆ¶é—œéµå­—(ORé‚è¼¯): {user_keywords}")
            logger.info(f"ğŸ¤– AIé—œéµå­—(ORé‚è¼¯): {ai_keywords}")
            
            # æ­¥é©Ÿ1ï¼šé©—è­‰APIå¯†é‘°
            if settings.REQUIRE_API_VALIDATION and not await self.verify_api_key(user_code):
                return PatentProcessingResult(
                    success=False,
                    error="GPSS APIå¯†é‘°é©—è­‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥å¯†é‘°æ˜¯å¦æ­£ç¢º"
                )
            
            # æ­¥é©Ÿ2ï¼šä½¿ç”¨AND/ORé‚è¼¯æœç´¢å°ˆåˆ©
            raw_patents = await self._search_patents_with_and_or_logic(
                user_keywords, ai_keywords, user_code, max_results
            )
            
            if not raw_patents:
                return PatentProcessingResult(
                    success=True,
                    results=[],
                    total_found=0,
                    message="æœªæ‰¾åˆ°ç›¸é—œå°ˆåˆ©",
                    query_info={
                        "description": description,
                        "user_keywords": user_keywords,
                        "ai_keywords": ai_keywords,
                        "search_logic": "(ç”¨æˆ¶é—œéµå­— OR ...) AND (AIé—œéµå­— OR ...)",
                        "search_time": time.time() - start_time
                    }
                )
            
            logger.info(f"âœ… AND/ORé‚è¼¯æœç´¢åˆ° {len(raw_patents)} ç­†åŸå§‹å°ˆåˆ©")
            
            # æ­¥é©Ÿ3ï¼šæ‰¹æ¬¡è™•ç†å°ˆåˆ©
            processed_patents = await self._process_patents_with_batching(raw_patents)
            
            # æ­¥é©Ÿ4ï¼šæ ¼å¼åŒ–çµæœï¼ˆä¿®å¾©ç‰ˆæœ¬ï¼‰
            formatted_results = self._format_search_results_fixed(processed_patents)
            
            execution_time = time.time() - start_time
            
            return PatentProcessingResult(
                success=True,
                results=formatted_results,
                total_found=len(formatted_results),
                message=f"AND/ORé‚è¼¯æŸ¥è©¢å®Œæˆï¼Œæ‰¾åˆ° {len(formatted_results)} ç­†å°ˆåˆ©",
                query_info={
                    "description": description,
                    "user_keywords": user_keywords,
                    "ai_keywords": ai_keywords,
                    "search_logic": "(ç”¨æˆ¶é—œéµå­— OR ...) AND (AIé—œéµå­— OR ...)",
                    "search_time": execution_time,
                    "processed_count": len(processed_patents),
                    "batch_processing": True
                }
            )
            
        except Exception as e:
            logger.error(f"âŒ AND/ORé‚è¼¯æŸ¥è©¢å¤±æ•—: {e}")
            return PatentProcessingResult(
                success=False,
                error=f"AND/ORé‚è¼¯æŸ¥è©¢å¤±æ•—: {str(e)}"
            )

    async def process_condition_search(
        self, 
        search_params: Dict[str, Any], 
        user_code: str, 
        max_results: int = 1000
    ) -> PatentProcessingResult:
        """æµç¨‹Bï¼šæ¢ä»¶æŸ¥è©¢"""
        start_time = time.time()
        
        try:
            logger.info(f"é–‹å§‹æ¢ä»¶æŸ¥è©¢: {search_params}")
            
            # æ­¥é©Ÿ1ï¼šé©—è­‰APIå¯†é‘°
            if settings.REQUIRE_API_VALIDATION and not await self.verify_api_key(user_code):
                return PatentProcessingResult(
                    success=False,
                    error="GPSS APIå¯†é‘°é©—è­‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥å¯†é‘°æ˜¯å¦æ­£ç¢º"
                )
            
            # æ­¥é©Ÿ2ï¼šæ ¹æ“šæ¢ä»¶æœç´¢å°ˆåˆ©
            raw_patents = await self._search_patents_with_conditions(search_params, user_code, max_results)
            
            if not raw_patents:
                return PatentProcessingResult(
                    success=True,
                    results=[],
                    total_found=0,
                    message="æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„å°ˆåˆ©",
                    query_info={
                        "search_conditions": search_params,
                        "search_time": time.time() - start_time
                    }
                )
            
            logger.info(f"æœç´¢åˆ° {len(raw_patents)} ç­†åŸå§‹å°ˆåˆ©")
            
            # æ­¥é©Ÿ3ï¼šæ‰¹æ¬¡è™•ç†å°ˆåˆ©
            processed_patents = await self._process_patents_with_batching(raw_patents)
            
            # æ­¥é©Ÿ4ï¼šæ ¼å¼åŒ–çµæœï¼ˆä¿®å¾©ç‰ˆæœ¬ï¼‰
            formatted_results = self._format_search_results_fixed(processed_patents)
            
            execution_time = time.time() - start_time
            
            return PatentProcessingResult(
                success=True,
                results=formatted_results,
                total_found=len(formatted_results),
                message=f"æ¢ä»¶æŸ¥è©¢å®Œæˆï¼Œæ‰¾åˆ° {len(formatted_results)} ç­†å°ˆåˆ©",
                query_info={
                    "search_conditions": search_params,
                    "search_time": execution_time,
                    "processed_count": len(processed_patents),
                    "batch_processing": True
                }
            )
            
        except Exception as e:
            logger.error(f"æ¢ä»¶æŸ¥è©¢å¤±æ•—: {e}")
            return PatentProcessingResult(
                success=False,
                error=f"æ¢ä»¶æŸ¥è©¢å¤±æ•—: {str(e)}"
            )

    async def _search_patents_with_and_or_logic(
        self, 
        user_keywords: List[str], 
        ai_keywords: List[str], 
        user_code: str, 
        max_results: int
    ) -> List[Dict]:
        """ä½¿ç”¨AND/ORé—œéµå­—é‚è¼¯æœç´¢å°ˆåˆ©"""
        try:
            logger.info(f"ğŸ” åŸ·è¡ŒAND/ORé‚è¼¯æœç´¢")
            logger.info(f"ğŸ“ ç”¨æˆ¶é—œéµå­—(OR): {user_keywords}")
            logger.info(f"ğŸ¤– AIé—œéµå­—(OR): {ai_keywords}")
            
            # ä½¿ç”¨GPSSæœå‹™çš„AND/ORæœç´¢æ–¹æ³•
            raw_result = await self.gpss_service.search_patents_with_and_or_logic(
                user_code=user_code,
                user_keywords=user_keywords if user_keywords else None,
                ai_keywords=ai_keywords if ai_keywords else None,
                databases=['TWA','TWB','USA','USB','JPA','JPB','EPA','EPB','KPA','KPB','CNA','CNB','WO','SEAA','SEAB','OTA','OTB'],
                max_results=max_results
            )
            
            # è§£æGPSSå›æ‡‰
            patents = self.gpss_service.parse_gpss_response(raw_result)
            logger.info(f"âœ… AND/ORé‚è¼¯æˆåŠŸè§£æ {len(patents)} ç­†å°ˆåˆ©")
            return patents
                
        except Exception as e:
            logger.error(f"âŒ AND/ORå°ˆåˆ©æœç´¢å¤±æ•—: {e}")
            raise Exception(f"AND/ORå°ˆåˆ©æœç´¢å¤±æ•—: {str(e)}")

    async def _search_patents_with_keywords(self, keywords: List[str], user_code: str, max_results: int) -> List[Dict]:
        """ä½¿ç”¨é—œéµå­—æœç´¢å°ˆåˆ©ï¼ˆå‚³çµ±æ–¹å¼ï¼‰"""
        try:
            logger.info(f"ä½¿ç”¨GPSS APIæœç´¢å°ˆåˆ©ï¼Œé—œéµå­—: {keywords}")
            
            # ä½¿ç”¨çœŸå¯¦GPSS API
            raw_result = await self.gpss_service.search_patents_raw(
                user_code=user_code,
                keywords=keywords,
                databases=['TWA','TWB','USA','USB','JPA','JPB','EPA','EPB','KPA','KPB','CNA','CNB','WO','SEAA','SEAB','OTA','OTB'],
                max_results=max_results
            )
            
            # è§£æGPSSå›æ‡‰
            patents = self.gpss_service.parse_gpss_response(raw_result)
            logger.info(f"æˆåŠŸè§£æ {len(patents)} ç­†å°ˆåˆ©")
            return patents
                
        except Exception as e:
            logger.error(f"å°ˆåˆ©æœç´¢å¤±æ•—: {e}")
            raise Exception(f"å°ˆåˆ©æœç´¢å¤±æ•—: {str(e)}")

    async def _search_patents_with_conditions(self, conditions: Dict[str, Any], user_code: str, max_results: int) -> List[Dict]:
        """æ ¹æ“šæ¢ä»¶æœç´¢å°ˆåˆ©"""
        try:
            logger.info(f"ä½¿ç”¨çœŸå¯¦GPSS APIæ¢ä»¶æœç´¢ï¼Œæ¢ä»¶: {conditions}")
            
            # å°‡æ¢ä»¶è½‰æ›ç‚ºGPSS APIæ ¼å¼
            search_conditions = {}
            
            # åŸºæœ¬æ¢ä»¶
            if conditions.get('applicant'):
                search_conditions['applicant'] = conditions['applicant']
            if conditions.get('inventor'):
                search_conditions['inventor'] = conditions['inventor']
            if conditions.get('patent_number'):
                search_conditions['patent_number'] = conditions['patent_number']
            if conditions.get('application_number'):
                search_conditions['application_number'] = conditions['application_number']
            if conditions.get('ipc_class'):
                search_conditions['ipc_class'] = conditions['ipc_class']
            if conditions.get('title_keyword'):
                search_conditions['title'] = conditions['title_keyword']
            if conditions.get('abstract_keyword'):
                search_conditions['abstract'] = conditions['abstract_keyword']
            if conditions.get('claims_keyword'):
                search_conditions['claims'] = conditions['claims_keyword']
            
            # æ—¥æœŸæ¢ä»¶
            date_params = {}
            if conditions.get('application_date_from') or conditions.get('application_date_to'):
                date_range = []
                if conditions.get('application_date_from'):
                    date_range.append(conditions['application_date_from'].replace('-', ''))
                if conditions.get('application_date_to'):
                    if len(date_range) == 1:
                        date_range.append(conditions['application_date_to'].replace('-', ''))
                    else:
                        date_range = [conditions['application_date_to'].replace('-', '')]
                
                if len(date_range) == 2:
                    date_params['gpss_AD'] = f"{date_range[0]}:{date_range[1]}"
                elif len(date_range) == 1:
                    date_params['gpss_AD'] = f"{date_range[0]}:"
            
            if conditions.get('publication_date_from') or conditions.get('publication_date_to'):
                date_range = []
                if conditions.get('publication_date_from'):
                    date_range.append(conditions['publication_date_from'].replace('-', ''))
                if conditions.get('publication_date_to'):
                    if len(date_range) == 1:
                        date_range.append(conditions['publication_date_to'].replace('-', ''))
                    else:
                        date_range = [conditions['publication_date_to'].replace('-', '')]
                
                if len(date_range) == 2:
                    date_params['gpss_ID'] = f"{date_range[0]}:{date_range[1]}"
                elif len(date_range) == 1:
                    date_params['gpss_ID'] = f"{date_range[0]}:"
            
            # ä½¿ç”¨çœŸå¯¦GPSS API
            raw_result = await self.gpss_service.search_patents_raw(
                user_code=user_code,
                search_conditions=search_conditions,
                databases=['TWA','TWB','USA','USB','JPA','JPB','EPA','EPB','KPA','KPB','CNA','CNB','WO','SEAA','SEAB','OTA','OTB'],
                max_results=max_results,
                **date_params
            )
            
            # è§£æGPSSå›æ‡‰
            patents = self.gpss_service.parse_gpss_response(raw_result)
            logger.info(f"æˆåŠŸè§£æ {len(patents)} ç­†å°ˆåˆ©")
            return patents
                
        except Exception as e:
            logger.error(f"æ¢ä»¶æœç´¢å¤±æ•—: {e}")
            raise Exception(f"æ¢ä»¶æœç´¢å¤±æ•—: {str(e)}")

    async def generate_keywords_from_description(self, description: str) -> Dict[str, Any]:
        """ä½¿ç”¨Qwenå¾æŠ€è¡“æè¿°ç”Ÿæˆ5å€‹é—œéµå­—"""
        try:
            if not self.qwen_service:
                return {"keywords": self._extract_fallback_keywords(description)}
        
            result = await self.qwen_service.generate_keywords_from_description(description, num_keywords=5)
            return result
        
        except Exception as e:
            logger.warning(f"Qwené—œéµå­—ç”Ÿæˆå¤±æ•—ï¼Œä½¿ç”¨fallback: {e}")
            return {"keywords": self._extract_fallback_keywords(description)}

    async def generate_keywords_with_synonyms_from_description(self, description: str) -> Dict:
        """
        å¾æŠ€è¡“æè¿°ç”Ÿæˆé—œéµå­—å’ŒåŒç¾©è©
        """
        try:
            if not self.qwen_service:
                raise Exception("Qwenæœå‹™æœªåˆå§‹åŒ–")

            result = await self.qwen_service.generate_keywords_with_synonyms(description, num_keywords=3, num_synonyms=5)
            return result

        except Exception as e:
            logger.error(f"ç”Ÿæˆé—œéµå­—å’ŒåŒç¾©è©å¤±æ•—: {e}")
            # ä½¿ç”¨fallbackæ–¹æ³•
            return self._generate_keywords_synonyms_fallback(description, 3, 5)

    def _generate_keywords_synonyms_fallback(self, description: str, num_keywords: int, num_synonyms: int) -> Dict:
        """
        Fallbackæ–¹æ³•ï¼šç•¶Qwenå¤±æ•—æ™‚ä½¿ç”¨çš„é—œéµå­—å’ŒåŒç¾©è©ç”Ÿæˆ
        """
        # åŸºæœ¬çš„æŠ€è¡“è©å½™å°æ‡‰è¡¨
        tech_synonyms = {
            "æ¸¬è©¦": ["test", "æª¢æ¸¬", "æ¸¬é‡", "æª¢é©—", "é©—è­‰"],
            "æ§åˆ¶": ["control", "æ§åˆ¶å™¨", "èª¿ç¯€", "ç®¡ç†", "æ“æ§"],
            "è‡ªå‹•åŒ–": ["automation", "è‡ªå‹•", "æ™ºèƒ½åŒ–", "ç„¡äººåŒ–", "æ©Ÿæ¢°åŒ–"],
            "åŠå°é«”": ["semiconductor", "æ™¶ç‰‡", "IC", "èŠ¯ç‰‡", "é›»å­å…ƒä»¶"],
            "æ¢é‡": ["probe", "æ¸¬è©¦é‡", "æ¢æ¸¬å™¨", "æª¢æ¸¬å™¨", "æ¸¬è©¦é ­"],
            "ç²¾å¯†": ["precision", "ç²¾ç¢º", "é«˜ç²¾åº¦", "å¾®ç±³ç´š", "æº–ç¢º"],
            "ç³»çµ±": ["system", "è¨­å‚™", "è£ç½®", "æ©Ÿå°", "å¹³å°"],
            "è™•ç†": ["processing", "è™•ç†å™¨", "åŠ å·¥", "æ“ä½œ", "é‹ç®—"],
            "æª¢æ¸¬": ["detection", "æª¢æŸ¥", "ç›£æ¸¬", "è­˜åˆ¥", "æ„Ÿæ¸¬"],
            "æ™¶åœ“": ["wafer", "çŸ½ç‰‡", "åŸºæ¿", "æ™¶ç‰‡", "åœ“ç‰‡"]
        }

        # å¾æè¿°ä¸­æå–é—œéµè©
        keywords_found = []
        description_lower = description.lower()

        for main_word, synonyms in tech_synonyms.items():
            if main_word in description or any(syn.lower() in description_lower for syn in synonyms):
                keywords_found.append({
                    "keyword": main_word,
                    "synonyms": synonyms[:num_synonyms]
                })
                if len(keywords_found) >= num_keywords:
                    break
                    
        # å¦‚æœæ‰¾åˆ°çš„ä¸å¤ ï¼Œæ·»åŠ é€šç”¨æŠ€è¡“è©å½™
        if len(keywords_found) < num_keywords:
            default_keywords = [
                {"keyword": "æª¢æ¸¬", "synonyms": ["detection", "æ¸¬è©¦", "æª¢é©—", "æ¸¬é‡", "åˆ†æ"]},
                {"keyword": "æ§åˆ¶", "synonyms": ["control", "èª¿ç¯€", "ç®¡ç†", "æ“æ§", "æŒ‡ä»¤"]},
                {"keyword": "è‡ªå‹•åŒ–", "synonyms": ["automation", "æ™ºèƒ½", "æ©Ÿæ¢°", "ç„¡äºº", "è‡ªå‹•"]}
            ]
            
            for default in default_keywords:
                if len(keywords_found) >= num_keywords:
                    break
                if not any(item['keyword'] == default['keyword'] for item in keywords_found):
                    keywords_found.append(default)

        return {
            "keywords_with_synonyms": keywords_found[:num_keywords],
            "source": "fallback"
        }

    async def process_tech_description_search_with_synonyms(
        self,
        description: str,
        selected_keyword_groups: List[Dict[str, Any]],
        custom_keywords: List[str],
        user_code: str,
        max_results: int = 200
    ) -> PatentProcessingResult:
        """
        è™•ç†å¸¶åŒç¾©è©çš„æŠ€è¡“æè¿°æœç´¢
        æ§‹å»ºGPSS APIå¯ç†è§£çš„AND/ORæŸ¥è©¢èªæ³•ï¼Œç›´æ¥ç™¼é€çµ¦GPSSè³‡æ–™åº«åŸ·è¡Œ
        """
        try:
            start_time = time.time()
            logger.info(f"ğŸ” é–‹å§‹åŸ·è¡Œå¸¶åŒç¾©è©çš„æŠ€è¡“æè¿°æœç´¢")

            # é©—è­‰APIå¯†é‘°
            if not await self.verify_api_key(user_code):
                return PatentProcessingResult(
                    success=False,
                    error="GPSS APIé©—è­‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥é©—è­‰ç¢¼æ˜¯å¦æ­£ç¢º"
                )

            # ğŸ¯ æ§‹å»ºGPSS APIå¯ç†è§£çš„æŸ¥è©¢èªæ³•
            gpss_query = self._build_gpss_and_or_query(selected_keyword_groups, custom_keywords)

            logger.info(f"ğŸ” æ§‹å»ºçš„GPSSæŸ¥è©¢èªæ³•: {gpss_query}")

            # ğŸš€ ç›´æ¥ä½¿ç”¨GPSS APIåŸ·è¡Œè¤‡é›œAND/ORé‚è¼¯æŸ¥è©¢
            raw_result = await self.gpss_service.search_patents_with_complex_and_or_logic(
                user_code=user_code,
                complex_query=gpss_query,
                databases=['TWA','TWB','USA','USB','JPA','JPB','EPA','EPB','KPA','KPB','CNA','CNB','WO','SEAA','SEAB','OTA','OTB'],
                max_results=max_results
            )

            # è§£æGPSSå›æ‡‰
            patents = self.gpss_service.parse_gpss_response(raw_result)

            if not patents:
                return PatentProcessingResult(
                    success=True,
                    results=[],
                    total_found=0,
                    message="æœªæ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„å°ˆåˆ©",
                    query_info={
                        "gpss_query": gpss_query,
                        "keyword_groups": selected_keyword_groups,
                        "custom_keywords": custom_keywords,
                        "execution_time": time.time() - start_time
                    }
                )

            logger.info(f"ğŸ“‹ GPSSæœç´¢è¿”å› {len(patents)} ç­†å°ˆåˆ©")

            # ä½¿ç”¨Qwenç‚ºæ¯å€‹å°ˆåˆ©ç”ŸæˆæŠ€è¡“ç‰¹å¾µå’ŒåŠŸæ•ˆ
            processed_patents = await self._process_patents_with_qwen_features(patents[:max_results])

            execution_time = time.time() - start_time

            return PatentProcessingResult(
                success=True,
                results=processed_patents,
                total_found=len(processed_patents),
                message=f"æˆåŠŸæª¢ç´¢ä¸¦è™•ç†äº† {len(processed_patents)} ç­†å°ˆåˆ©",
                query_info={
                    "gpss_query": gpss_query,
                    "keyword_groups": selected_keyword_groups,
                    "custom_keywords": custom_keywords,
                    "execution_time": execution_time,
                    "search_logic": "GPSSè³‡æ–™åº«åŸ·è¡ŒAND/ORé‚è¼¯"
                }
            )

        except Exception as e:
            logger.error(f"âŒ å¸¶åŒç¾©è©çš„æŠ€è¡“æè¿°æœç´¢å¤±æ•—: {e}")
            return PatentProcessingResult(
                success=False,
                error=f"æœç´¢å¤±æ•—: {str(e)}"
            )

    def _build_gpss_and_or_query(
        self, 
        selected_keyword_groups: List[Dict[str, Any]], 
        custom_keywords: List[str]
    ) -> str:
        """
        æ§‹å»ºGPSS APIå¯ç†è§£çš„AND/ORæŸ¥è©¢èªæ³•

        ä¾‹å¦‚ï¼š(é—œéµå­—1 OR åŒç¾©è©1-1 OR åŒç¾©è©1-2) AND (é—œéµå­—2 OR åŒç¾©è©2-1 OR åŒç¾©è©2-2)

        GPSS APIèªæ³•åƒè€ƒï¼š
        - OR: ç”¨ OR é€£æ¥
        - AND: ç”¨ AND é€£æ¥  
        - æ‹¬è™Ÿ: ç”¨ () åŒ…åœ
        """
        try:
            query_parts = []

            # è™•ç†é—œéµå­—çµ„åˆï¼ˆæ¯çµ„å…§ç”¨ORï¼Œçµ„é–“ç”¨ANDï¼‰
            for group_index, group in enumerate(selected_keyword_groups):
                group_terms = []

                # æ·»åŠ ä¸»é—œéµå­—ï¼ˆå¦‚æœé¸ä¸­ï¼‰
                if group.get('keyword_selected', False):
                    keyword = group.get('keyword', '')
                    if keyword:
                        group_terms.append(keyword)

                # æ·»åŠ é¸ä¸­çš„åŒç¾©è©
                selected_synonyms = group.get('selected_synonyms', [])
                group_terms.extend(selected_synonyms)

                # å¦‚æœé€™çµ„æœ‰é¸ä¸­çš„è©å½™ï¼Œæ§‹å»ºçµ„å…§ORé‚è¼¯
                if group_terms:
                    # æ¸…ç†å’Œè½‰ç¾©è©å½™
                    cleaned_terms = [self._escape_gpss_term(term) for term in group_terms if term.strip()]
                    if cleaned_terms:
                        # çµ„å…§ç”¨ORé€£æ¥
                        group_query = " or ".join(cleaned_terms)
                        query_parts.append(f"({group_query})")

                        logger.debug(f"é—œéµå­—çµ„{group_index + 1}: {group_query}")

            # è™•ç†è‡ªå®šç¾©é—œéµå­—
            if custom_keywords:
                custom_terms = []
                for custom_kw in custom_keywords:
                    if custom_kw and custom_kw.strip():
                        cleaned_kw = self._escape_gpss_term(custom_kw.strip())
                        custom_terms.append(cleaned_kw)

                if custom_terms:
                    custom_query = " or ".join(custom_terms)
                    query_parts.append(f"({custom_query})")
                    logger.debug(f"è‡ªå®šç¾©é—œéµå­—: {custom_query}")

            # çµ„é–“ç”¨ANDé€£æ¥
            if not query_parts:
                return ""

            final_query = " and ".join(query_parts)

            logger.info(f"ğŸ”§ GPSSæŸ¥è©¢èªæ³•æ§‹å»ºå®Œæˆ:")
            logger.info(f"   - é—œéµå­—çµ„æ•¸: {len(selected_keyword_groups)}")
            logger.info(f"   - è‡ªå®šç¾©é—œéµå­—æ•¸: {len(custom_keywords) if custom_keywords else 0}")
            logger.info(f"   - æœ€çµ‚æŸ¥è©¢: {final_query}")

            return final_query

        except Exception as e:
            logger.error(f"âŒ æ§‹å»ºGPSSæŸ¥è©¢èªæ³•å¤±æ•—: {e}")
            return ""

    def _escape_gpss_term(self, term: str) -> str:
        """
        è½‰ç¾©GPSS APIæŸ¥è©¢è©å½™

        æ ¹æ“šGPSS APIè¦ç¯„è™•ç†ç‰¹æ®Šå­—ç¬¦
        """
        if not term:
            return ""

        # ç§»é™¤é¦–å°¾ç©ºç™½
        term = term.strip()

        # å¦‚æœåŒ…å«ç©ºæ ¼æˆ–ç‰¹æ®Šå­—ç¬¦ï¼Œç”¨å¼•è™ŸåŒ…åœ
        if ' ' in term or any(char in term for char in ['(', ')', '&', '|', '"']):
            # è½‰ç¾©å…§éƒ¨çš„å¼•è™Ÿ
            term = term.replace('"', '\\"')
            return f'"{term}"'
        
        return term

    async def _process_patents_with_qwen_features(self, patents: List[Dict]) -> List[Dict]:
        """
        ä½¿ç”¨Qwenç‚ºå°ˆåˆ©åˆ—è¡¨ç”ŸæˆæŠ€è¡“ç‰¹å¾µå’ŒåŠŸæ•ˆ
        """
        processed_patents = []

        # ä½¿ç”¨ä¿¡è™Ÿé‡æ§åˆ¶ä¸¦ç™¼
        async def process_single_patent(patent, index):
            async with self.semaphore:
                try:
                    logger.info(f"ğŸ“ è™•ç†å°ˆåˆ© {index + 1}/{len(patents)}: {patent.get('title', 'N/A')[:50]}...")

                    # æº–å‚™å°ˆåˆ©æ•¸æ“š
                    patent_data = {
                        'title': patent.get('title', ''),
                        'abstract': patent.get('abstract', ''),
                        'claims': patent.get('claims', ''),
                        'main_claim': patent.get('claims', '')[:500] if patent.get('claims') else ''
                    }

                    # ä½¿ç”¨Qwenç”ŸæˆæŠ€è¡“ç‰¹å¾µå’ŒåŠŸæ•ˆ
                    features_result = await self.qwen_service.generate_technical_features_and_effects(patent_data)

                    # çµ„è£æœ€çµ‚çµæœ
                    processed_patent = {
                        "åºè™Ÿ": index + 1,
                        "å°ˆåˆ©åç¨±": patent.get('title', 'N/A'),
                        "å…¬é–‹å…¬å‘Šè™Ÿ": patent.get('publication_number', patent.get('id', 'N/A')),
                        "æ‘˜è¦": patent.get('abstract', 'N/A'),
                        "å°ˆåˆ©ç¯„åœ": patent.get('claims', 'N/A'),
                        "æŠ€è¡“ç‰¹å¾µ": features_result.get('technical_features', ['æŠ€è¡“ç‰¹å¾µç”Ÿæˆä¸­...']),
                        "æŠ€è¡“åŠŸæ•ˆ": features_result.get('technical_effects', ['æŠ€è¡“åŠŸæ•ˆç”Ÿæˆä¸­...']),

                        # ä¿ç•™åŸå§‹è³‡æ–™ä¾›å…¶ä»–ç”¨é€”
                        "ç”³è«‹äºº": patent.get('applicants', 'N/A'),
                        "ç™¼æ˜äºº": patent.get('inventors', 'N/A'),
                        "åœ‹å®¶": patent.get('country', 'TW'),
                        "ç”³è«‹æ—¥": patent.get('application_date', 'N/A'),
                        "å…¬é–‹æ—¥": patent.get('publication_date', 'N/A'),
                        "IPCåˆ†é¡": patent.get('ipc_classes', 'N/A')
                    }

                    return processed_patent

                except Exception as e:
                    logger.error(f"âŒ è™•ç†å°ˆåˆ© {index + 1} å¤±æ•—: {e}")
                    # è¿”å›åŸºæœ¬ä¿¡æ¯ï¼Œæ¨™è¨˜è™•ç†å¤±æ•—
                    return {
                        "åºè™Ÿ": index + 1,
                        "å°ˆåˆ©åç¨±": patent.get('title', 'N/A'),
                        "å…¬é–‹å…¬å‘Šè™Ÿ": patent.get('publication_number', patent.get('id', 'N/A')),
                        "æ‘˜è¦": patent.get('abstract', 'N/A'),
                        "å°ˆåˆ©ç¯„åœ": patent.get('claims', 'N/A'),
                        "æŠ€è¡“ç‰¹å¾µ": ['æŠ€è¡“ç‰¹å¾µç”Ÿæˆå¤±æ•—'],
                        "æŠ€è¡“åŠŸæ•ˆ": ['æŠ€è¡“åŠŸæ•ˆç”Ÿæˆå¤±æ•—'],
                        "ç”³è«‹äºº": patent.get('applicants', 'N/A'),
                        "ç™¼æ˜äºº": patent.get('inventors', 'N/A'),
                        "åœ‹å®¶": patent.get('country', 'TW'),
                        "ç”³è«‹æ—¥": patent.get('application_date', 'N/A'),
                        "å…¬é–‹æ—¥": patent.get('publication_date', 'N/A'),
                        "IPCåˆ†é¡": patent.get('ipc_classes', 'N/A')
                    }

        # ä¸¦è¡Œè™•ç†æ‰€æœ‰å°ˆåˆ©
        tasks = [process_single_patent(patent, i) for i, patent in enumerate(patents)]
    
        # åˆ†æ‰¹è™•ç†ä»¥é¿å…éè¼‰
        for i in range(0, len(tasks), self.BATCH_SIZE):
            batch = tasks[i:i + self.BATCH_SIZE]
            batch_results = await asyncio.gather(*batch, return_exceptions=True)
        
            for result in batch_results:
                if isinstance(result, Exception):
                    logger.error(f"âŒ æ‰¹æ¬¡è™•ç†å¤±æ•—: {result}")
                else:
                    processed_patents.append(result)

            # æ‰¹æ¬¡é–“å»¶é²
            if i + self.BATCH_SIZE < len(tasks):
                await asyncio.sleep(self.BATCH_DELAY)

        logger.info(f"âœ… æˆåŠŸè™•ç† {len(processed_patents)} ç­†å°ˆåˆ©")
        return processed_patents

    def _build_synonym_search_query(
        self, 
        selected_keyword_groups: List[Dict[str, Any]], 
        custom_keywords: List[str]
    ) -> str:
        """
        æ§‹å»ºå¸¶åŒç¾©è©çš„æœç´¢æŸ¥è©¢
        é‚è¼¯ï¼š(é—œéµå­—1 OR åŒç¾©è©1-1 OR åŒç¾©è©1-2) AND (é—œéµå­—2 OR åŒç¾©è©2-1 OR åŒç¾©è©2-2)
        """
        query_parts = []

        # è™•ç†é—œéµå­—çµ„åˆï¼ˆæ¯çµ„å…§ç”¨ORï¼Œçµ„é–“ç”¨ANDï¼‰
        for group in selected_keyword_groups:
            group_terms = []

            # æ·»åŠ ä¸»é—œéµå­—ï¼ˆå¦‚æœé¸ä¸­ï¼‰
            if group.get('keyword_selected', False):
                keyword = group.get('keyword', '')
                if keyword:
                    group_terms.append(keyword)

            # æ·»åŠ é¸ä¸­çš„åŒç¾©è©
            selected_synonyms = group.get('selected_synonyms', [])
            group_terms.extend(selected_synonyms)

            # å¦‚æœé€™çµ„æœ‰é¸ä¸­çš„è©å½™ï¼ŒåŠ å…¥æŸ¥è©¢
            if group_terms:
                # çµ„å…§ç”¨ORé€£æ¥
                group_query = " OR ".join([f'"{term}"' for term in group_terms])
                query_parts.append(f"({group_query})")
        
        # è™•ç†è‡ªå®šç¾©é—œéµå­—
        if custom_keywords:
            custom_query = " OR ".join([f'"{kw.strip()}"' for kw in custom_keywords if kw.strip()])
            if custom_query:
                query_parts.append(f"({custom_query})")

        # çµ„é–“ç”¨ANDé€£æ¥
        final_query = " AND ".join(query_parts)

        return final_query

    async def _process_patents_with_batching(self, patents: List[Dict]) -> List[Dict]:
        """æ‰¹æ¬¡è™•ç†å°ˆåˆ©"""
        if not patents:
            return []
        
        total_patents = len(patents)
        processed_patents = []
        failed_count = 0
        
        logger.info(f"ğŸ”§ é–‹å§‹æ‰¹æ¬¡è™•ç† {total_patents} ç­†å°ˆåˆ©ï¼Œæ‰¹æ¬¡å¤§å°: {self.BATCH_SIZE}")
        
        batch_size = self._get_optimal_batch_size(total_patents)
        
        for batch_idx in range(0, total_patents, batch_size):
            batch_end = min(batch_idx + batch_size, total_patents)
            batch_patents = patents[batch_idx:batch_end]
            batch_num = (batch_idx // batch_size) + 1
            total_batches = (total_patents + batch_size - 1) // batch_size
            
            logger.info(f"ğŸ“¦ è™•ç†ç¬¬ {batch_num}/{total_batches} æ‰¹ï¼Œå°ˆåˆ© {batch_idx+1}-{batch_end}")
            
            batch_results = await self._process_batch_with_concurrency_control(batch_patents)
            
            successful_in_batch = sum(1 for result in batch_results if not result.get('_processing_error'))
            failed_in_batch = len(batch_results) - successful_in_batch
            failed_count += failed_in_batch
            
            processed_patents.extend(batch_results)
            
            logger.info(f"âœ… æ‰¹æ¬¡ {batch_num} å®Œæˆï¼ŒæˆåŠŸ: {successful_in_batch}, å¤±æ•—: {failed_in_batch}")
            
            if batch_end < total_patents:
                delay_time = self._get_dynamic_delay(failed_in_batch, len(batch_results))
                logger.info(f"â³ æ‰¹æ¬¡é–“ä¼‘æ¯ {delay_time:.1f} ç§’...")
                await asyncio.sleep(delay_time)
        
        success_rate = ((total_patents - failed_count) / total_patents * 100) if total_patents > 0 else 0
        logger.info(f"ğŸ¯ æ‰¹æ¬¡è™•ç†å®Œæˆï¼Œç¸½è¨ˆ: {total_patents}, æˆåŠŸ: {total_patents - failed_count}, å¤±æ•—: {failed_count}, æˆåŠŸç‡: {success_rate:.1f}%")
        
        return processed_patents

    def _get_optimal_batch_size(self, total_count: int) -> int:
        """æ ¹æ“šå°ˆåˆ©ç¸½æ•¸å‹•æ…‹èª¿æ•´æ‰¹æ¬¡å¤§å°"""
        if total_count <= 50:
            return 10
        elif total_count <= 200:
            return 15
        else:
            return 20

    def _get_dynamic_delay(self, failed_count: int, total_count: int) -> float:
        """æ ¹æ“šå¤±æ•—ç‡å‹•æ…‹èª¿æ•´å»¶é²æ™‚é–“"""
        failure_rate = failed_count / total_count if total_count > 0 else 0
        
        if failure_rate > 0.3:
            return self.BATCH_DELAY * 2.0
        elif failure_rate > 0.1:
            return self.BATCH_DELAY * 1.5
        else:
            return self.BATCH_DELAY

    async def _process_batch_with_concurrency_control(self, batch_patents: List[Dict]) -> List[Dict]:
        """ä½¿ç”¨ä¸¦ç™¼æ§åˆ¶è™•ç†å–®å€‹æ‰¹æ¬¡"""
        
        async def process_with_semaphore(patent):
            async with self.semaphore:
                await asyncio.sleep(self.REQUEST_DELAY)
                return await self._process_single_patent_with_retry(patent)
        
        tasks = [process_with_semaphore(patent) for patent in batch_patents]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.warning(f"è™•ç†å°ˆåˆ©å¤±æ•— (æ‰¹æ¬¡å…§ç´¢å¼• {i}): {result}")
                patent_with_error = batch_patents[i].copy()
                patent_with_error['_processing_error'] = str(result)
                processed_results.append(patent_with_error)
            else:
                processed_results.append(result)
        
        return processed_results

    async def _process_single_patent_with_retry(self, patent: Dict) -> Dict:
        """è™•ç†å–®ä¸€å°ˆåˆ©ä¸¦æ”¯æŒé‡è©¦æ©Ÿåˆ¶"""
        for attempt in range(self.MAX_RETRIES + 1):
            try:
                return await self._process_single_patent_simple(patent)
            except Exception as e:
                if attempt < self.MAX_RETRIES:
                    wait_time = self.RETRY_DELAY * (2 ** attempt)
                    logger.warning(f"è™•ç†å°ˆåˆ©å¤±æ•—ï¼Œ{wait_time:.1f}ç§’å¾Œé‡è©¦ (å˜—è©¦ {attempt + 1}/{self.MAX_RETRIES + 1}): {e}")
                    await asyncio.sleep(wait_time)
                else:
                    logger.error(f"è™•ç†å°ˆåˆ©æœ€çµ‚å¤±æ•—ï¼Œå·²é”æœ€å¤§é‡è©¦æ¬¡æ•¸: {e}")
                    raise

    async def _process_single_patent_simple(self, patent: Dict) -> Dict:
        """è™•ç†å–®ä¸€å°ˆåˆ©ï¼šåªç”ŸæˆæŠ€è¡“ç‰¹å¾µå’ŒåŠŸæ•ˆ"""
        try:
            enhanced_patent = patent.copy()
            
            # ç”ŸæˆæŠ€è¡“ç‰¹å¾µå’ŒåŠŸæ•ˆ
            try:
                features_result = await asyncio.wait_for(
                    self._generate_tech_features_and_effects(patent),
                    timeout=60.0
                )
                
                if isinstance(features_result, Exception):
                    logger.warning(f"æŠ€è¡“ç‰¹å¾µç”Ÿæˆå¤±æ•—: {features_result}")
                    enhanced_patent['technical_features'] = ["æŠ€è¡“ç‰¹å¾µæå–å¤±æ•—"]
                    enhanced_patent['technical_effects'] = ["æŠ€è¡“åŠŸæ•ˆæå–å¤±æ•—"]
                else:
                    enhanced_patent['technical_features'] = features_result.get('technical_features', [])
                    enhanced_patent['technical_effects'] = features_result.get('technical_effects', [])
                    
            except asyncio.TimeoutError:
                logger.warning(f"æŠ€è¡“ç‰¹å¾µç”Ÿæˆè¶…æ™‚ï¼Œä½¿ç”¨fallback: {patent.get('title', 'Unknown')[:50]}...")
                fallback_result = self._generate_fallback_features(patent)
                enhanced_patent['technical_features'] = fallback_result.get('technical_features', [])
                enhanced_patent['technical_effects'] = fallback_result.get('technical_effects', [])
            
            return enhanced_patent
            
        except Exception as e:
            logger.error(f"è™•ç†å–®ä¸€å°ˆåˆ©å¤±æ•—: {e}")
            patent['_processing_error'] = str(e)
            return patent

    async def _generate_tech_features_and_effects(self, patent: Dict) -> Dict:
        """ç”ŸæˆæŠ€è¡“ç‰¹å¾µå’ŒåŠŸæ•ˆ"""
        try:
            if not self.qwen_service:
                return self._generate_fallback_features(patent)
            
            result = await self.qwen_service.generate_technical_features_and_effects(patent)
            return result
            
        except Exception as e:
            logger.warning(f"æŠ€è¡“ç‰¹å¾µç”Ÿæˆå¤±æ•—: {e}")
            return self._generate_fallback_features(patent)

    def _format_search_results_fixed(self, patents: List[Dict]) -> List[Dict]:
        """ğŸ”§ ä¿®å¾©ç‰ˆï¼šæ ¼å¼åŒ–æœç´¢çµæœç‚ºå‰ç«¯æ‰€éœ€æ ¼å¼ï¼ˆä¿®å¾©ç”³è«‹äººå’Œåœ‹å®¶é¡¯ç¤ºï¼‰"""
        formatted_results = []
    
        for i, patent in enumerate(patents):
            # ğŸ”§ ä¿®å¾©ï¼šè™•ç†ç”³è«‹äººä¿¡æ¯
            applicants_raw = patent.get('applicants', 'N/A')
            if isinstance(applicants_raw, list):
                applicants_str = '; '.join(applicants_raw) if applicants_raw else 'N/A'
            else:
                applicants_str = str(applicants_raw) if applicants_raw and applicants_raw != 'N/A' else 'N/A'
            
            # ğŸ”§ ä¿®å¾©ï¼šè™•ç†åœ‹å®¶ä¿¡æ¯
            country_code = patent.get('country', 'TW')
            
            # åœ‹å®¶ä»£ç¢¼åˆ°é¡¯ç¤ºåç¨±çš„æ˜ å°„
            country_display_mapping = {
                'TW': 'TW',
                'US': 'US',
                'JP': 'JP',
                'EP': 'EP',
                'KR': 'KR',
                'CN': 'CN',
                'WO': 'WO',
                'SEA': 'SEA',
                'OTHER': 'å…¶ä»–'
            }
            
            country_display = country_display_mapping.get(country_code, country_code)
            
            formatted_patent = {
                "åºè™Ÿ": i + 1,
                "å°ˆåˆ©åç¨±": patent.get('title', 'N/A'),
                "ç”³è«‹äºº": applicants_str,  # ğŸ”§ ä¿®å¾©å¾Œçš„ç”³è«‹äºº
                "åœ‹å®¶": country_display,   # ğŸ”§ ä¿®å¾©å¾Œçš„åœ‹å®¶é¡¯ç¤º
                "ç”³è«‹è™Ÿ": patent.get('application_number', 'N/A'),
                "å…¬é–‹å…¬å‘Šè™Ÿ": patent.get('publication_number', 'N/A'),
                "æ‘˜è¦": patent.get('abstract', 'N/A'),
                "å°ˆåˆ©ç¯„åœ": patent.get('claims', 'N/A'),
                "æŠ€è¡“ç‰¹å¾µ": patent.get('technical_features', []),
                "æŠ€è¡“åŠŸæ•ˆ": patent.get('technical_effects', []),
                
                # ğŸ”§ æ–°å¢ï¼šå°ˆåˆ©é€£çµï¼ˆæ ¹æ“šå…¬é–‹å…¬å‘Šè™Ÿç”Ÿæˆï¼‰
                "å°ˆåˆ©é€£çµ": self._generate_patent_link(patent.get('publication_number', '')),
                
                # ğŸ”§ æ–°å¢ï¼šèª¿è©¦ä¿¡æ¯ï¼ˆé–‹ç™¼éšæ®µä½¿ç”¨ï¼‰
                "_debug_info": {
                    "raw_applicants": patent.get('applicants'),
                    "raw_country": patent.get('country'),
                    "database": patent.get('database', 'Unknown')
                }
            }
        
            if patent.get('_processing_error'):
                formatted_patent["è™•ç†ç‹€æ…‹"] = f"éƒ¨åˆ†å¤±æ•—: {patent['_processing_error']}"
            
            # ğŸ”§ è¨˜éŒ„ä¿®å¾©çµæœ
            logger.debug(f"æ ¼å¼åŒ–å°ˆåˆ© {i+1}: ç”³è«‹äºº={applicants_str}, åœ‹å®¶={country_display}")
            
            formatted_results.append(formatted_patent)
    
        logger.info(f"âœ… å®Œæˆæ ¼å¼åŒ– {len(formatted_results)} ç­†å°ˆåˆ©çµæœï¼ˆç”³è«‹äººå’Œåœ‹å®¶å·²ä¿®å¾©ï¼‰")
        return formatted_results

    def _generate_patent_link(self, publication_number: str) -> str:
        """ğŸ”§ æ–°å¢ï¼šæ ¹æ“šå…¬é–‹å…¬å‘Šè™Ÿç”ŸæˆGPSSå°ˆåˆ©é€£çµ"""
        if not publication_number or publication_number == 'N/A':
            return ''
        
        # GPSSå°ˆåˆ©è©³ç´°é é¢é€£çµæ ¼å¼
        base_url = "https://tiponet.tipo.gov.tw/gpss4/gpsskmc/gpssbkm"
        return f"{base_url}?!!FRURL{publication_number}"

    def _extract_fallback_keywords(self, description: str) -> List[str]:
        """fallbacké—œéµå­—æå–"""
        keywords = []
    
        tech_terms = {
            'æ¸¬è©¦': 'test', 'æª¢æ¸¬': 'inspection', 'è‡ªå‹•åŒ–': 'automation',
            'æ§åˆ¶': 'control', 'ç²¾å¯†': 'precision', 'åŠå°é«”': 'semiconductor',
            'æ¢é‡': 'probe', 'ç³»çµ±': 'system', 'æ©Ÿæ¢°': 'mechanical'
        }

        description_lower = description.lower()
        for chinese, english in tech_terms.items():
            if chinese in description or english in description_lower:
                keywords.append(chinese)

        if not keywords:
            keywords = ['æ¸¬è©¦', 'ç³»çµ±', 'æ§åˆ¶', 'ç²¾å¯†', 'è‡ªå‹•åŒ–']

        return keywords[:5]

    def _generate_fallback_features(self, patent: Dict) -> Dict:
        """ç”ŸæˆfallbackæŠ€è¡“ç‰¹å¾µå’ŒåŠŸæ•ˆ"""
        title = patent.get('title', '')
    
        features = []
        effects = []
    
        if 'æ¸¬è©¦' in title:
            features.append('æ¸¬è©¦åŠŸèƒ½æ¨¡çµ„')
            effects.append('æå‡æ¸¬è©¦æ•ˆç‡')
        if 'è‡ªå‹•' in title:
            features.append('è‡ªå‹•åŒ–æ§åˆ¶ç³»çµ±')
            effects.append('æ¸›å°‘äººå·¥æ“ä½œ')
        if 'æ§åˆ¶' in title:
            features.append('ç²¾å¯†æ§åˆ¶æ©Ÿåˆ¶')
            effects.append('æé«˜æ§åˆ¶ç²¾åº¦')

        if not features:
            features = ['å‰µæ–°æŠ€è¡“è¨­è¨ˆ']
            effects = ['æŠ€è¡“æ€§èƒ½æå‡']

        return {
            'technical_features': features,
            'technical_effects': effects,
            'source': 'fallback'
        }

    def get_processing_stats(self) -> Dict:
        """ç²å–è™•ç†çµ±è¨ˆä¿¡æ¯"""
        return {
            "batch_size": self.BATCH_SIZE,
            "batch_delay": self.BATCH_DELAY,
            "max_concurrent_requests": self.MAX_CONCURRENT_REQUESTS,
            "request_delay": self.REQUEST_DELAY,
            "max_retries": self.MAX_RETRIES,
            "retry_delay": self.RETRY_DELAY,
            "initialized": self.initialized,
            "verified_api_keys": len(self.verified_api_keys),
            "classification_enabled": False,
            "confidence_tracking": False,
            "applicant_country_fixed": True,  # ğŸ”§ æ¨™è¨˜å·²ä¿®å¾©ç”³è«‹äººå’Œåœ‹å®¶å•é¡Œ
            "features": ["qwen_keywords", "tech_features", "gpss_search", "excel_processing", "applicant_country_fix"]
        }

    # Excelè™•ç†ç›¸é—œæ–¹æ³•ä¿æŒä¸è®Š...
    async def process_excel_batch_analysis(
        self,
        excel_file_content: bytes,
        filename: str = "unknown.xlsx"
    ) -> Dict[str, Any]:
        """è™•ç†Excelæª”æ¡ˆæ‰¹é‡åˆ†æ"""
        start_time = time.time()
        session_id = str(uuid.uuid4())
        
        try:
            logger.info(f"ğŸ“Š é–‹å§‹è™•ç†Excelæ‰¹é‡åˆ†æ: {filename}, å¤§å°: {len(excel_file_content)} bytes")
            
            if not self.initialized:
                await self.initialize()
            
            # æ­¥é©Ÿ1: è§£æExcelæª”æ¡ˆ
            try:
                df = pd.read_excel(BytesIO(excel_file_content))
                logger.info(f"ğŸ“‹ Excelè§£ææˆåŠŸï¼Œå…± {len(df)} è¡Œè³‡æ–™")
            except Exception as e:
                raise Exception(f"Excelæª”æ¡ˆè§£æå¤±æ•—: {str(e)}")
            
            # æ­¥é©Ÿ2: é©—è­‰å¿…è¦æ¬„ä½ä¸¦æ¨™æº–åŒ–æ¬„ä½åç¨±
            df_processed = self._validate_and_normalize_excel_columns(df)
            
            # æ­¥é©Ÿ3: è³‡æ–™æ¸…ç†å’Œé è™•ç†
            df_cleaned = self._clean_excel_data(df_processed)
            
            if len(df_cleaned) == 0:
                raise Exception("Excelæª”æ¡ˆä¸­æ²’æœ‰æœ‰æ•ˆçš„å°ˆåˆ©è³‡æ–™")
            
            # æ­¥é©Ÿ4: é™åˆ¶è™•ç†æ•¸é‡
            max_records = 500
            if len(df_cleaned) > max_records:
                df_cleaned = df_cleaned.head(max_records)
                logger.warning(f"âš ï¸ Excelè³‡æ–™è¶…é{max_records}ç­†ï¼Œåªè™•ç†å‰{max_records}ç­†")
            
            # æ­¥é©Ÿ5: æ‰¹é‡è™•ç†å°ˆåˆ©åˆ†æ
            analysis_results = await self._process_excel_patents_batch(
                df_cleaned, session_id
            )
            
            # æ­¥é©Ÿ6: çµ±è¨ˆåˆ†æçµæœ
            stats = self._calculate_excel_analysis_stats(analysis_results)
            
            execution_time = time.time() - start_time
            
            logger.info(f"âœ… Excelæ‰¹é‡åˆ†æå®Œæˆï¼Œè€—æ™‚: {execution_time:.2f}ç§’")
            
            return {
                "success": True,
                "session_id": session_id,
                "filename": filename,
                "total_count": len(df),
                "processed_count": stats["success_count"],
                "failed_count": stats["error_count"],
                "results": analysis_results["success_results"],
                "errors": analysis_results["error_messages"][:10],
                "statistics": stats,
                "execution_time": execution_time,
                "message": f"Excelåˆ†æå®Œæˆï¼ŒæˆåŠŸè™•ç† {stats['success_count']} ç­†å°ˆåˆ©è³‡æ–™"
            }
            
        except Exception as e:
            logger.error(f"âŒ Excelæ‰¹é‡åˆ†æå¤±æ•—: {e}")
            return {
                "success": False,
                "session_id": session_id,
                "filename": filename,
                "error": str(e),
                "execution_time": time.time() - start_time
            }
    
    def _validate_and_normalize_excel_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """é©—è­‰ä¸¦æ¨™æº–åŒ–Excelæ¬„ä½åç¨±"""
        required_columns = ['å…¬é–‹å…¬å‘Šè™Ÿ', 'å°ˆåˆ©åç¨±', 'æ‘˜è¦', 'å°ˆåˆ©ç¯„åœ']
        
        column_mapping = {
            'publication_number': 'å…¬é–‹å…¬å‘Šè™Ÿ',
            'patent_number': 'å…¬é–‹å…¬å‘Šè™Ÿ',
            'pub_no': 'å…¬é–‹å…¬å‘Šè™Ÿ',
            'patent_id': 'å…¬é–‹å…¬å‘Šè™Ÿ',
            
            'title': 'å°ˆåˆ©åç¨±',
            'patent_title': 'å°ˆåˆ©åç¨±',
            'name': 'å°ˆåˆ©åç¨±',
            'patent_name': 'å°ˆåˆ©åç¨±',
            
            'abstract': 'æ‘˜è¦',
            'summary': 'æ‘˜è¦',
            'description': 'æ‘˜è¦',
            
            'claims': 'å°ˆåˆ©ç¯„åœ',
            'patent_claims': 'å°ˆåˆ©ç¯„åœ',
            'claim': 'å°ˆåˆ©ç¯„åœ',
            'patent_scope': 'å°ˆåˆ©ç¯„åœ'
        }
        
        missing_columns = []
        df_columns = df.columns.tolist()
        
        for required_col in required_columns:
            if required_col not in df_columns:
                missing_columns.append(required_col)
        
        if missing_columns:
            rename_dict = {}
            for english_col, chinese_col in column_mapping.items():
                if english_col in df_columns and chinese_col in missing_columns:
                    rename_dict[english_col] = chinese_col
                    missing_columns.remove(chinese_col)
            
            if rename_dict:
                df = df.rename(columns=rename_dict)
                logger.info(f"ğŸ”„ æ¬„ä½æ˜ å°„: {rename_dict}")
        
        if missing_columns:
            raise Exception(f"Excelæª”æ¡ˆç¼ºå°‘å¿…è¦æ¬„ä½: {missing_columns}")
        
        return df
    
    def _clean_excel_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ¸…ç†Excelè³‡æ–™"""
        df = df.dropna(subset=['å…¬é–‹å…¬å‘Šè™Ÿ', 'å°ˆåˆ©åç¨±'], how='all')
        
        df['æ‘˜è¦'] = df['æ‘˜è¦'].fillna('')
        df['å°ˆåˆ©ç¯„åœ'] = df['å°ˆåˆ©ç¯„åœ'].fillna('')
        
        df = df[
            (df['å…¬é–‹å…¬å‘Šè™Ÿ'].notna()) & 
            (df['å°ˆåˆ©åç¨±'].notna()) &
            (df['å…¬é–‹å…¬å‘Šè™Ÿ'].astype(str).str.strip() != '') &
            (df['å°ˆåˆ©åç¨±'].astype(str).str.strip() != '')
        ]
        
        df = df.reset_index(drop=True)
        
        logger.info(f"ğŸ“‹ è³‡æ–™æ¸…ç†å®Œæˆï¼Œæœ‰æ•ˆè³‡æ–™: {len(df)} ç­†")
        return df
    
    async def _process_excel_patents_batch(
        self, 
        df: pd.DataFrame, 
        session_id: str
    ) -> Dict[str, Any]:
        """æ‰¹é‡è™•ç†Excelä¸­çš„å°ˆåˆ©è³‡æ–™"""
        success_results = []
        error_messages = []
        
        batch_size = 20
        total_batches = (len(df) + batch_size - 1) // batch_size
        
        logger.info(f"ğŸ”§ é–‹å§‹æ‰¹é‡è™•ç† {len(df)} ç­†å°ˆåˆ©ï¼Œåˆ†ç‚º {total_batches} æ‰¹")
        
        for batch_idx in range(0, len(df), batch_size):
            batch_end = min(batch_idx + batch_size, len(df))
            batch_df = df.iloc[batch_idx:batch_end]
            batch_num = (batch_idx // batch_size) + 1
            
            logger.info(f"ğŸ“¦ è™•ç†ç¬¬ {batch_num}/{total_batches} æ‰¹ï¼Œå°ˆåˆ© {batch_idx+1}-{batch_end}")
            
            batch_results = await self._process_single_excel_batch(
                batch_df, session_id, batch_idx
            )
            
            for result in batch_results:
                if result.get('error'):
                    error_messages.append(result['error'])
                else:
                    success_results.append(result)
            
            if batch_end < len(df):
                await asyncio.sleep(0.3)
        
        return {
            "success_results": success_results,
            "error_messages": error_messages
        }
    
    async def _process_single_excel_batch(
        self, 
        batch_df: pd.DataFrame, 
        session_id: str, 
        start_index: int
    ) -> List[Dict]:
        """è™•ç†å–®å€‹Excelæ‰¹æ¬¡"""
        tasks = []
        
        for idx, row in batch_df.iterrows():
            patent_data = {
                'title': str(row.get('å°ˆåˆ©åç¨±', '')).strip() if pd.notna(row.get('å°ˆåˆ©åç¨±')) else '',
                'abstract': str(row.get('æ‘˜è¦', '')).strip() if pd.notna(row.get('æ‘˜è¦')) else '',
                'claims': str(row.get('å°ˆåˆ©ç¯„åœ', '')).strip() if pd.notna(row.get('å°ˆåˆ©ç¯„åœ')) else '',
                'publication_number': str(row.get('å…¬é–‹å…¬å‘Šè™Ÿ', '')).strip() if pd.notna(row.get('å…¬é–‹å…¬å‘Šè™Ÿ')) else '',
                'excel_row_index': start_index + idx + 2,
                'sequence_number': start_index + idx + 1
            }
            
            task = self._process_single_excel_patent_with_semaphore(patent_data, session_id)
            tasks.append(task)
        
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        processed_results = []
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.warning(f"è™•ç†Excelå°ˆåˆ©å¤±æ•— (æ‰¹æ¬¡å…§ç´¢å¼• {i}): {result}")
                processed_results.append({
                    'error': f"ç¬¬ {start_index + i + 2} è¡Œè™•ç†å¤±æ•—: {str(result)}"
                })
            else:
                processed_results.append(result)
        
        return processed_results
    
    async def _process_single_excel_patent_with_semaphore(
        self, 
        patent_data: Dict, 
        session_id: str
    ) -> Dict:
        """ä½¿ç”¨ä¿¡è™Ÿé‡æ§åˆ¶ä¸¦ç™¼çš„å–®å°ˆåˆ©è™•ç†"""
        async with self.semaphore:
            await asyncio.sleep(self.REQUEST_DELAY)
            return await self._process_single_excel_patent(patent_data, session_id)
    
    async def _process_single_excel_patent(self, patent_data: Dict, session_id: str) -> Dict:
        """è™•ç†å–®å€‹Excelå°ˆåˆ©è³‡æ–™"""
        try:
            if not patent_data['title'] or not patent_data['publication_number']:
                return {
                    'error': f"ç¬¬ {patent_data['excel_row_index']} è¡Œè³‡æ–™ä¸å®Œæ•´ (ç¼ºå°‘å°ˆåˆ©åç¨±æˆ–å…¬é–‹å…¬å‘Šè™Ÿ)"
                }
        
            try:
                features_result = await asyncio.wait_for(
                    self._generate_tech_features_and_effects(patent_data),
                    timeout=60.0
                )
            except asyncio.TimeoutError:
                logger.warning(f"ç¬¬ {patent_data['excel_row_index']} è¡ŒæŠ€è¡“ç‰¹å¾µç”Ÿæˆè¶…æ™‚")
                features_result = self._generate_fallback_features(patent_data)
            except Exception as e:
                logger.warning(f"ç¬¬ {patent_data['excel_row_index']} è¡ŒæŠ€è¡“ç‰¹å¾µç”Ÿæˆå¤±æ•—: {e}")
                features_result = self._generate_fallback_features(patent_data)

            result = {
                "åºè™Ÿ": patent_data['sequence_number'],
                "å°ˆåˆ©åç¨±": patent_data['title'],
                "å…¬é–‹å…¬å‘Šè™Ÿ": patent_data['publication_number'],
                "æ‘˜è¦": self._truncate_text(patent_data['abstract'], 500),
                "å°ˆåˆ©ç¯„åœ": self._truncate_text(patent_data['claims'], 500),
                "æŠ€è¡“ç‰¹å¾µ": features_result.get('technical_features', []),
                "æŠ€è¡“åŠŸæ•ˆ": features_result.get('technical_effects', []),
                "åˆ†ææ–¹æ³•": features_result.get('source', 'unknown'),
                "session_id": session_id,
                "åŸå§‹è¡Œè™Ÿ": patent_data['excel_row_index']
            }

            return result

        except Exception as e:
            logger.error(f"è™•ç†ç¬¬ {patent_data.get('excel_row_index', 'unknown')} è¡Œå°ˆåˆ©å¤±æ•—: {e}")
            return {
                'error': f"ç¬¬ {patent_data.get('excel_row_index', 'unknown')} è¡Œè™•ç†å¤±æ•—: {str(e)}"
            }
    
    def _calculate_excel_analysis_stats(self, analysis_results: Dict) -> Dict:
        """è¨ˆç®—Excelåˆ†æçµ±è¨ˆ"""
        success_results = analysis_results["success_results"]
        error_messages = analysis_results["error_messages"]
    
        success_count = len(success_results)
        error_count = len(error_messages)
        total_count = success_count + error_count
    
        analysis_methods = {"qwen_api": 0, "fallback": 0, "other": 0}
    
        if success_results:
            for result in success_results:
                method = result.get('åˆ†ææ–¹æ³•', 'other')
                if method in analysis_methods:
                    analysis_methods[method] += 1
                else:
                    analysis_methods["other"] += 1

        return {
            "success_count": success_count,
            "error_count": error_count,
            "total_count": total_count,
            "success_rate": (success_count / total_count * 100) if total_count > 0 else 0,
            "analysis_methods": analysis_methods
        }

    def _truncate_text(self, text: str, max_length: int) -> str:
        """æˆªæ–·æ–‡æœ¬åˆ°æŒ‡å®šé•·åº¦"""
        if not text:
            return ""
        
        text = str(text).strip()
        if len(text) <= max_length:
            return text
        
        return text[:max_length-3] + "..."
    
    def get_excel_processing_stats(self) -> Dict:
        """ç²å–Excelè™•ç†çµ±è¨ˆä¿¡æ¯"""
        return {
            "max_file_size_mb": 10,
            "max_records": 500,
            "supported_formats": [".xlsx", ".xls"],
            "required_columns": ["å…¬é–‹å…¬å‘Šè™Ÿ", "å°ˆåˆ©åç¨±", "æ‘˜è¦", "å°ˆåˆ©ç¯„åœ"],
            "batch_size": self.BATCH_SIZE,
            "processing_stats": self.get_processing_stats(),
            "classification_enabled": False,
            "applicant_country_fixed": True  # ğŸ”§ æ¨™è¨˜å·²ä¿®å¾©
        }

# å–®ä¾‹å¯¦ä¾‹
improved_patent_processing_service = ImprovedPatentProcessingService()